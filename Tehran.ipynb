{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parsa-fathi/Hybrid-Renewable-Energy-System-/blob/master/Tehran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ntLdTvyGH_6",
        "outputId": "f8bd2bfe-2e04-4715-9e40-cf8828efab5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DBkgW6SGCiY",
        "outputId": "1cf9b1b0-0593-4090-9a81-0781d7a416f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - binary_accuracy: 0.8065 - loss: 0.6301 - val_binary_accuracy: 0.7875 - val_loss: 0.5379\n",
            "Epoch 2/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8114 - loss: 0.5056 - val_binary_accuracy: 0.8725 - val_loss: 0.4301\n",
            "Epoch 3/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8922 - loss: 0.4037 - val_binary_accuracy: 0.9300 - val_loss: 0.3405\n",
            "Epoch 4/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9369 - loss: 0.3202 - val_binary_accuracy: 0.9450 - val_loss: 0.2683\n",
            "Epoch 5/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9543 - loss: 0.2544 - val_binary_accuracy: 0.9613 - val_loss: 0.2135\n",
            "Epoch 6/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9607 - loss: 0.2053 - val_binary_accuracy: 0.9675 - val_loss: 0.1736\n",
            "Epoch 7/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9618 - loss: 0.1702 - val_binary_accuracy: 0.9737 - val_loss: 0.1450\n",
            "Epoch 8/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9629 - loss: 0.1454 - val_binary_accuracy: 0.9787 - val_loss: 0.1242\n",
            "Epoch 9/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9652 - loss: 0.1276 - val_binary_accuracy: 0.9787 - val_loss: 0.1087\n",
            "Epoch 10/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9652 - loss: 0.1145 - val_binary_accuracy: 0.9800 - val_loss: 0.0968\n",
            "Epoch 11/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9672 - loss: 0.1044 - val_binary_accuracy: 0.9812 - val_loss: 0.0873\n",
            "Epoch 12/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9683 - loss: 0.0964 - val_binary_accuracy: 0.9862 - val_loss: 0.0797\n",
            "Epoch 13/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9706 - loss: 0.0900 - val_binary_accuracy: 0.9862 - val_loss: 0.0735\n",
            "Epoch 14/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9730 - loss: 0.0847 - val_binary_accuracy: 0.9875 - val_loss: 0.0683\n",
            "Epoch 15/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9734 - loss: 0.0804 - val_binary_accuracy: 0.9875 - val_loss: 0.0640\n",
            "Epoch 16/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9744 - loss: 0.0767 - val_binary_accuracy: 0.9862 - val_loss: 0.0604\n",
            "Epoch 17/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9738 - loss: 0.0736 - val_binary_accuracy: 0.9837 - val_loss: 0.0572\n",
            "Epoch 18/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9751 - loss: 0.0709 - val_binary_accuracy: 0.9850 - val_loss: 0.0545\n",
            "Epoch 19/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9749 - loss: 0.0685 - val_binary_accuracy: 0.9862 - val_loss: 0.0521\n",
            "Epoch 20/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9753 - loss: 0.0664 - val_binary_accuracy: 0.9850 - val_loss: 0.0500\n",
            "Epoch 21/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9761 - loss: 0.0645 - val_binary_accuracy: 0.9850 - val_loss: 0.0482\n",
            "Epoch 22/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9765 - loss: 0.0629 - val_binary_accuracy: 0.9850 - val_loss: 0.0466\n",
            "Epoch 23/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9766 - loss: 0.0614 - val_binary_accuracy: 0.9875 - val_loss: 0.0451\n",
            "Epoch 24/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9766 - loss: 0.0601 - val_binary_accuracy: 0.9875 - val_loss: 0.0438\n",
            "Epoch 25/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9765 - loss: 0.0588 - val_binary_accuracy: 0.9875 - val_loss: 0.0426\n",
            "Epoch 26/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9769 - loss: 0.0577 - val_binary_accuracy: 0.9875 - val_loss: 0.0415\n",
            "Epoch 27/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9777 - loss: 0.0567 - val_binary_accuracy: 0.9900 - val_loss: 0.0404\n",
            "Epoch 28/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9794 - loss: 0.0557 - val_binary_accuracy: 0.9900 - val_loss: 0.0395\n",
            "Epoch 29/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9799 - loss: 0.0548 - val_binary_accuracy: 0.9900 - val_loss: 0.0386\n",
            "Epoch 30/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9805 - loss: 0.0540 - val_binary_accuracy: 0.9900 - val_loss: 0.0377\n",
            "Epoch 31/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9805 - loss: 0.0532 - val_binary_accuracy: 0.9900 - val_loss: 0.0369\n",
            "Epoch 32/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9810 - loss: 0.0524 - val_binary_accuracy: 0.9900 - val_loss: 0.0362\n",
            "Epoch 33/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9810 - loss: 0.0517 - val_binary_accuracy: 0.9912 - val_loss: 0.0354\n",
            "Epoch 34/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9812 - loss: 0.0510 - val_binary_accuracy: 0.9900 - val_loss: 0.0347\n",
            "Epoch 35/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.9813 - loss: 0.0504 - val_binary_accuracy: 0.9912 - val_loss: 0.0341\n",
            "Epoch 36/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9817 - loss: 0.0497 - val_binary_accuracy: 0.9912 - val_loss: 0.0334\n",
            "Epoch 37/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 0.9823 - loss: 0.0491 - val_binary_accuracy: 0.9912 - val_loss: 0.0328\n",
            "Epoch 38/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9825 - loss: 0.0485 - val_binary_accuracy: 0.9912 - val_loss: 0.0322\n",
            "Epoch 39/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9825 - loss: 0.0479 - val_binary_accuracy: 0.9912 - val_loss: 0.0316\n",
            "Epoch 40/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9825 - loss: 0.0474 - val_binary_accuracy: 0.9912 - val_loss: 0.0311\n",
            "Epoch 41/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9825 - loss: 0.0468 - val_binary_accuracy: 0.9925 - val_loss: 0.0306\n",
            "Epoch 42/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9825 - loss: 0.0463 - val_binary_accuracy: 0.9925 - val_loss: 0.0301\n",
            "Epoch 43/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9826 - loss: 0.0458 - val_binary_accuracy: 0.9925 - val_loss: 0.0296\n",
            "Epoch 44/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9826 - loss: 0.0453 - val_binary_accuracy: 0.9925 - val_loss: 0.0291\n",
            "Epoch 45/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9828 - loss: 0.0449 - val_binary_accuracy: 0.9925 - val_loss: 0.0287\n",
            "Epoch 46/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9829 - loss: 0.0444 - val_binary_accuracy: 0.9925 - val_loss: 0.0282\n",
            "Epoch 47/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9833 - loss: 0.0440 - val_binary_accuracy: 0.9937 - val_loss: 0.0278\n",
            "Epoch 48/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9834 - loss: 0.0435 - val_binary_accuracy: 0.9937 - val_loss: 0.0274\n",
            "Epoch 49/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9834 - loss: 0.0431 - val_binary_accuracy: 0.9937 - val_loss: 0.0270\n",
            "Epoch 50/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9834 - loss: 0.0427 - val_binary_accuracy: 0.9937 - val_loss: 0.0266\n",
            "Epoch 51/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9834 - loss: 0.0423 - val_binary_accuracy: 0.9937 - val_loss: 0.0263\n",
            "Epoch 52/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9834 - loss: 0.0419 - val_binary_accuracy: 0.9937 - val_loss: 0.0259\n",
            "Epoch 53/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9834 - loss: 0.0415 - val_binary_accuracy: 0.9937 - val_loss: 0.0256\n",
            "Epoch 54/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9837 - loss: 0.0411 - val_binary_accuracy: 0.9937 - val_loss: 0.0252\n",
            "Epoch 55/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9837 - loss: 0.0407 - val_binary_accuracy: 0.9937 - val_loss: 0.0249\n",
            "Epoch 56/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9839 - loss: 0.0404 - val_binary_accuracy: 0.9937 - val_loss: 0.0246\n",
            "Epoch 57/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9843 - loss: 0.0400 - val_binary_accuracy: 0.9937 - val_loss: 0.0243\n",
            "Epoch 58/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9844 - loss: 0.0397 - val_binary_accuracy: 0.9937 - val_loss: 0.0240\n",
            "Epoch 59/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9844 - loss: 0.0393 - val_binary_accuracy: 0.9937 - val_loss: 0.0237\n",
            "Epoch 60/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9852 - loss: 0.0390 - val_binary_accuracy: 0.9937 - val_loss: 0.0234\n",
            "Epoch 61/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9860 - loss: 0.0387 - val_binary_accuracy: 0.9937 - val_loss: 0.0231\n",
            "Epoch 62/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9860 - loss: 0.0383 - val_binary_accuracy: 0.9937 - val_loss: 0.0228\n",
            "Epoch 63/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9860 - loss: 0.0380 - val_binary_accuracy: 0.9937 - val_loss: 0.0226\n",
            "Epoch 64/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9860 - loss: 0.0377 - val_binary_accuracy: 0.9937 - val_loss: 0.0223\n",
            "Epoch 65/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9860 - loss: 0.0374 - val_binary_accuracy: 0.9937 - val_loss: 0.0221\n",
            "Epoch 66/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9868 - loss: 0.0371 - val_binary_accuracy: 0.9937 - val_loss: 0.0219\n",
            "Epoch 67/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9868 - loss: 0.0369 - val_binary_accuracy: 0.9937 - val_loss: 0.0216\n",
            "Epoch 68/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9870 - loss: 0.0366 - val_binary_accuracy: 0.9937 - val_loss: 0.0214\n",
            "Epoch 69/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9870 - loss: 0.0363 - val_binary_accuracy: 0.9950 - val_loss: 0.0212\n",
            "Epoch 70/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9870 - loss: 0.0360 - val_binary_accuracy: 0.9950 - val_loss: 0.0210\n",
            "Epoch 71/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9871 - loss: 0.0358 - val_binary_accuracy: 0.9950 - val_loss: 0.0208\n",
            "Epoch 72/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9871 - loss: 0.0355 - val_binary_accuracy: 0.9950 - val_loss: 0.0206\n",
            "Epoch 73/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9871 - loss: 0.0352 - val_binary_accuracy: 0.9950 - val_loss: 0.0204\n",
            "Epoch 74/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9871 - loss: 0.0350 - val_binary_accuracy: 0.9950 - val_loss: 0.0202\n",
            "Epoch 75/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9871 - loss: 0.0347 - val_binary_accuracy: 0.9950 - val_loss: 0.0200\n",
            "Epoch 76/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9872 - loss: 0.0345 - val_binary_accuracy: 0.9950 - val_loss: 0.0198\n",
            "Epoch 77/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9872 - loss: 0.0343 - val_binary_accuracy: 0.9950 - val_loss: 0.0196\n",
            "Epoch 78/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9874 - loss: 0.0340 - val_binary_accuracy: 0.9950 - val_loss: 0.0195\n",
            "Epoch 79/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9870 - loss: 0.0338 - val_binary_accuracy: 0.9950 - val_loss: 0.0193\n",
            "Epoch 80/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9872 - loss: 0.0336 - val_binary_accuracy: 0.9950 - val_loss: 0.0191\n",
            "Epoch 81/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9872 - loss: 0.0334 - val_binary_accuracy: 0.9950 - val_loss: 0.0190\n",
            "Epoch 82/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9873 - loss: 0.0331 - val_binary_accuracy: 0.9950 - val_loss: 0.0188\n",
            "Epoch 83/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9874 - loss: 0.0329 - val_binary_accuracy: 0.9962 - val_loss: 0.0186\n",
            "Epoch 84/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9872 - loss: 0.0327 - val_binary_accuracy: 0.9962 - val_loss: 0.0185\n",
            "Epoch 85/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9872 - loss: 0.0325 - val_binary_accuracy: 0.9962 - val_loss: 0.0183\n",
            "Epoch 86/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9875 - loss: 0.0323 - val_binary_accuracy: 0.9962 - val_loss: 0.0182\n",
            "Epoch 87/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9875 - loss: 0.0321 - val_binary_accuracy: 0.9962 - val_loss: 0.0181\n",
            "Epoch 88/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9877 - loss: 0.0320 - val_binary_accuracy: 0.9962 - val_loss: 0.0179\n",
            "Epoch 89/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9877 - loss: 0.0318 - val_binary_accuracy: 0.9962 - val_loss: 0.0178\n",
            "Epoch 90/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9877 - loss: 0.0316 - val_binary_accuracy: 0.9962 - val_loss: 0.0176\n",
            "Epoch 91/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9877 - loss: 0.0314 - val_binary_accuracy: 0.9962 - val_loss: 0.0175\n",
            "Epoch 92/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9877 - loss: 0.0313 - val_binary_accuracy: 0.9962 - val_loss: 0.0174\n",
            "Epoch 93/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9879 - loss: 0.0311 - val_binary_accuracy: 0.9962 - val_loss: 0.0173\n",
            "Epoch 94/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9879 - loss: 0.0309 - val_binary_accuracy: 0.9962 - val_loss: 0.0172\n",
            "Epoch 95/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9879 - loss: 0.0308 - val_binary_accuracy: 0.9962 - val_loss: 0.0170\n",
            "Epoch 96/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9883 - loss: 0.0306 - val_binary_accuracy: 0.9962 - val_loss: 0.0169\n",
            "Epoch 97/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9884 - loss: 0.0305 - val_binary_accuracy: 0.9962 - val_loss: 0.0168\n",
            "Epoch 98/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9883 - loss: 0.0303 - val_binary_accuracy: 0.9962 - val_loss: 0.0167\n",
            "Epoch 99/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9883 - loss: 0.0301 - val_binary_accuracy: 0.9962 - val_loss: 0.0166\n",
            "Epoch 100/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9883 - loss: 0.0300 - val_binary_accuracy: 0.9962 - val_loss: 0.0165\n",
            "Epoch 101/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9883 - loss: 0.0299 - val_binary_accuracy: 0.9962 - val_loss: 0.0164\n",
            "Epoch 102/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9883 - loss: 0.0297 - val_binary_accuracy: 0.9962 - val_loss: 0.0163\n",
            "Epoch 103/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9883 - loss: 0.0296 - val_binary_accuracy: 0.9962 - val_loss: 0.0162\n",
            "Epoch 104/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9883 - loss: 0.0295 - val_binary_accuracy: 0.9962 - val_loss: 0.0161\n",
            "Epoch 105/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9883 - loss: 0.0293 - val_binary_accuracy: 0.9962 - val_loss: 0.0160\n",
            "Epoch 106/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9883 - loss: 0.0292 - val_binary_accuracy: 0.9962 - val_loss: 0.0159\n",
            "Epoch 107/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9883 - loss: 0.0291 - val_binary_accuracy: 0.9962 - val_loss: 0.0158\n",
            "Epoch 108/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9884 - loss: 0.0289 - val_binary_accuracy: 0.9962 - val_loss: 0.0157\n",
            "Epoch 109/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9881 - loss: 0.0288 - val_binary_accuracy: 0.9962 - val_loss: 0.0157\n",
            "Epoch 110/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9886 - loss: 0.0287 - val_binary_accuracy: 0.9962 - val_loss: 0.0156\n",
            "Epoch 111/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9886 - loss: 0.0286 - val_binary_accuracy: 0.9962 - val_loss: 0.0155\n",
            "Epoch 112/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9886 - loss: 0.0285 - val_binary_accuracy: 0.9962 - val_loss: 0.0154\n",
            "Epoch 113/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9886 - loss: 0.0284 - val_binary_accuracy: 0.9962 - val_loss: 0.0153\n",
            "Epoch 114/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9886 - loss: 0.0282 - val_binary_accuracy: 0.9962 - val_loss: 0.0153\n",
            "Epoch 115/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9886 - loss: 0.0281 - val_binary_accuracy: 0.9962 - val_loss: 0.0152\n",
            "Epoch 116/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9886 - loss: 0.0280 - val_binary_accuracy: 0.9962 - val_loss: 0.0151\n",
            "Epoch 117/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9886 - loss: 0.0279 - val_binary_accuracy: 0.9962 - val_loss: 0.0150\n",
            "Epoch 118/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0278 - val_binary_accuracy: 0.9962 - val_loss: 0.0150\n",
            "Epoch 119/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0277 - val_binary_accuracy: 0.9962 - val_loss: 0.0149\n",
            "Epoch 120/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0277 - val_binary_accuracy: 0.9962 - val_loss: 0.0148\n",
            "Epoch 121/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0276 - val_binary_accuracy: 0.9962 - val_loss: 0.0148\n",
            "Epoch 122/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0275 - val_binary_accuracy: 0.9962 - val_loss: 0.0147\n",
            "Epoch 123/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0274 - val_binary_accuracy: 0.9962 - val_loss: 0.0146\n",
            "Epoch 124/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0273 - val_binary_accuracy: 0.9962 - val_loss: 0.0146\n",
            "Epoch 125/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0272 - val_binary_accuracy: 0.9962 - val_loss: 0.0145\n",
            "Epoch 126/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0271 - val_binary_accuracy: 0.9962 - val_loss: 0.0145\n",
            "Epoch 127/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0270 - val_binary_accuracy: 0.9962 - val_loss: 0.0144\n",
            "Epoch 128/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0270 - val_binary_accuracy: 0.9962 - val_loss: 0.0143\n",
            "Epoch 129/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0269 - val_binary_accuracy: 0.9962 - val_loss: 0.0143\n",
            "Epoch 130/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0268 - val_binary_accuracy: 0.9962 - val_loss: 0.0142\n",
            "Epoch 131/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9884 - loss: 0.0267 - val_binary_accuracy: 0.9962 - val_loss: 0.0142\n",
            "Epoch 132/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9884 - loss: 0.0266 - val_binary_accuracy: 0.9962 - val_loss: 0.0141\n",
            "Epoch 133/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0266 - val_binary_accuracy: 0.9962 - val_loss: 0.0141\n",
            "Epoch 134/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0265 - val_binary_accuracy: 0.9962 - val_loss: 0.0140\n",
            "Epoch 135/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0264 - val_binary_accuracy: 0.9962 - val_loss: 0.0140\n",
            "Epoch 136/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0264 - val_binary_accuracy: 0.9962 - val_loss: 0.0139\n",
            "Epoch 137/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0263 - val_binary_accuracy: 0.9962 - val_loss: 0.0139\n",
            "Epoch 138/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9885 - loss: 0.0262 - val_binary_accuracy: 0.9962 - val_loss: 0.0138\n",
            "Epoch 139/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 0.9885 - loss: 0.0261 - val_binary_accuracy: 0.9962 - val_loss: 0.0138\n",
            "Epoch 140/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9885 - loss: 0.0261 - val_binary_accuracy: 0.9962 - val_loss: 0.0138\n",
            "Epoch 141/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 0.9885 - loss: 0.0260 - val_binary_accuracy: 0.9962 - val_loss: 0.0137\n",
            "Epoch 142/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9885 - loss: 0.0260 - val_binary_accuracy: 0.9962 - val_loss: 0.0137\n",
            "Epoch 143/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9885 - loss: 0.0259 - val_binary_accuracy: 0.9962 - val_loss: 0.0136\n",
            "Epoch 144/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9885 - loss: 0.0258 - val_binary_accuracy: 0.9962 - val_loss: 0.0136\n",
            "Epoch 145/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.9885 - loss: 0.0258 - val_binary_accuracy: 0.9962 - val_loss: 0.0135\n",
            "Epoch 146/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9885 - loss: 0.0257 - val_binary_accuracy: 0.9962 - val_loss: 0.0135\n",
            "Epoch 147/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9885 - loss: 0.0257 - val_binary_accuracy: 0.9962 - val_loss: 0.0135\n",
            "Epoch 148/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9885 - loss: 0.0256 - val_binary_accuracy: 0.9962 - val_loss: 0.0134\n",
            "Epoch 149/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0255 - val_binary_accuracy: 0.9962 - val_loss: 0.0134\n",
            "Epoch 150/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0255 - val_binary_accuracy: 0.9962 - val_loss: 0.0134\n",
            "Epoch 151/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0254 - val_binary_accuracy: 0.9962 - val_loss: 0.0133\n",
            "Epoch 152/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0254 - val_binary_accuracy: 0.9962 - val_loss: 0.0133\n",
            "Epoch 153/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0253 - val_binary_accuracy: 0.9962 - val_loss: 0.0133\n",
            "Epoch 154/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9885 - loss: 0.0253 - val_binary_accuracy: 0.9975 - val_loss: 0.0132\n",
            "Epoch 155/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0252 - val_binary_accuracy: 0.9975 - val_loss: 0.0132\n",
            "Epoch 156/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0252 - val_binary_accuracy: 0.9975 - val_loss: 0.0132\n",
            "Epoch 157/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0251 - val_binary_accuracy: 0.9975 - val_loss: 0.0131\n",
            "Epoch 158/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0251 - val_binary_accuracy: 0.9975 - val_loss: 0.0131\n",
            "Epoch 159/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9885 - loss: 0.0250 - val_binary_accuracy: 0.9975 - val_loss: 0.0131\n",
            "Epoch 160/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9885 - loss: 0.0250 - val_binary_accuracy: 0.9975 - val_loss: 0.0130\n",
            "Epoch 161/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9886 - loss: 0.0250 - val_binary_accuracy: 0.9975 - val_loss: 0.0130\n",
            "Epoch 162/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9886 - loss: 0.0249 - val_binary_accuracy: 0.9975 - val_loss: 0.0130\n",
            "Epoch 163/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9887 - loss: 0.0249 - val_binary_accuracy: 0.9975 - val_loss: 0.0129\n",
            "Epoch 164/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9887 - loss: 0.0248 - val_binary_accuracy: 0.9987 - val_loss: 0.0129\n",
            "Epoch 165/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9887 - loss: 0.0248 - val_binary_accuracy: 0.9987 - val_loss: 0.0129\n",
            "Epoch 166/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9887 - loss: 0.0247 - val_binary_accuracy: 0.9987 - val_loss: 0.0129\n",
            "Epoch 167/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9887 - loss: 0.0247 - val_binary_accuracy: 0.9987 - val_loss: 0.0128\n",
            "Epoch 168/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9887 - loss: 0.0247 - val_binary_accuracy: 0.9987 - val_loss: 0.0128\n",
            "Epoch 169/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9887 - loss: 0.0246 - val_binary_accuracy: 0.9987 - val_loss: 0.0128\n",
            "Epoch 170/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9887 - loss: 0.0246 - val_binary_accuracy: 0.9987 - val_loss: 0.0127\n",
            "Epoch 171/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9887 - loss: 0.0245 - val_binary_accuracy: 0.9987 - val_loss: 0.0127\n",
            "Epoch 172/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9889 - loss: 0.0245 - val_binary_accuracy: 0.9987 - val_loss: 0.0127\n",
            "Epoch 173/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9889 - loss: 0.0245 - val_binary_accuracy: 0.9987 - val_loss: 0.0127\n",
            "Epoch 174/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9889 - loss: 0.0244 - val_binary_accuracy: 0.9987 - val_loss: 0.0126\n",
            "Epoch 175/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9889 - loss: 0.0244 - val_binary_accuracy: 0.9987 - val_loss: 0.0126\n",
            "Epoch 176/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9889 - loss: 0.0244 - val_binary_accuracy: 0.9987 - val_loss: 0.0126\n",
            "Epoch 177/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9889 - loss: 0.0243 - val_binary_accuracy: 0.9987 - val_loss: 0.0126\n",
            "Epoch 178/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9889 - loss: 0.0243 - val_binary_accuracy: 0.9987 - val_loss: 0.0125\n",
            "Epoch 179/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9889 - loss: 0.0243 - val_binary_accuracy: 0.9987 - val_loss: 0.0125\n",
            "Epoch 180/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9889 - loss: 0.0242 - val_binary_accuracy: 0.9987 - val_loss: 0.0125\n",
            "Epoch 181/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9889 - loss: 0.0242 - val_binary_accuracy: 0.9987 - val_loss: 0.0125\n",
            "Epoch 182/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9889 - loss: 0.0242 - val_binary_accuracy: 0.9987 - val_loss: 0.0125\n",
            "Epoch 183/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9887 - loss: 0.0241 - val_binary_accuracy: 0.9987 - val_loss: 0.0124\n",
            "Epoch 184/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9890 - loss: 0.0241 - val_binary_accuracy: 0.9987 - val_loss: 0.0124\n",
            "Epoch 185/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9890 - loss: 0.0241 - val_binary_accuracy: 0.9987 - val_loss: 0.0124\n",
            "Epoch 186/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9890 - loss: 0.0240 - val_binary_accuracy: 0.9987 - val_loss: 0.0124\n",
            "Epoch 187/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9890 - loss: 0.0240 - val_binary_accuracy: 0.9987 - val_loss: 0.0123\n",
            "Epoch 188/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9890 - loss: 0.0240 - val_binary_accuracy: 0.9987 - val_loss: 0.0123\n",
            "Epoch 189/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9890 - loss: 0.0239 - val_binary_accuracy: 0.9987 - val_loss: 0.0123\n",
            "Epoch 190/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9890 - loss: 0.0239 - val_binary_accuracy: 0.9987 - val_loss: 0.0123\n",
            "Epoch 191/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9890 - loss: 0.0239 - val_binary_accuracy: 0.9975 - val_loss: 0.0123\n",
            "Epoch 192/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 0.9890 - loss: 0.0239 - val_binary_accuracy: 0.9987 - val_loss: 0.0122\n",
            "Epoch 193/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - binary_accuracy: 0.9890 - loss: 0.0238 - val_binary_accuracy: 0.9975 - val_loss: 0.0122\n",
            "Epoch 194/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9890 - loss: 0.0238 - val_binary_accuracy: 0.9975 - val_loss: 0.0122\n",
            "Epoch 195/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9890 - loss: 0.0238 - val_binary_accuracy: 0.9975 - val_loss: 0.0122\n",
            "Epoch 196/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9891 - loss: 0.0237 - val_binary_accuracy: 0.9975 - val_loss: 0.0122\n",
            "Epoch 197/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0237 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 198/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0237 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 199/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0237 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 200/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0236 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 201/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0236 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 202/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9891 - loss: 0.0236 - val_binary_accuracy: 0.9975 - val_loss: 0.0121\n",
            "Epoch 203/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9891 - loss: 0.0236 - val_binary_accuracy: 0.9975 - val_loss: 0.0120\n",
            "Epoch 204/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9891 - loss: 0.0235 - val_binary_accuracy: 0.9975 - val_loss: 0.0120\n",
            "Epoch 205/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9891 - loss: 0.0235 - val_binary_accuracy: 0.9975 - val_loss: 0.0120\n",
            "Epoch 206/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9891 - loss: 0.0235 - val_binary_accuracy: 0.9962 - val_loss: 0.0120\n",
            "Epoch 207/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9891 - loss: 0.0235 - val_binary_accuracy: 0.9975 - val_loss: 0.0120\n",
            "Epoch 208/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9891 - loss: 0.0234 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 209/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9891 - loss: 0.0234 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 210/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9894 - loss: 0.0234 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 211/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9893 - loss: 0.0234 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 212/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9893 - loss: 0.0233 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 213/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0233 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 214/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0233 - val_binary_accuracy: 0.9962 - val_loss: 0.0119\n",
            "Epoch 215/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9893 - loss: 0.0233 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 216/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0232 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 217/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9893 - loss: 0.0232 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 218/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9893 - loss: 0.0232 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 219/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9893 - loss: 0.0232 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 220/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9893 - loss: 0.0232 - val_binary_accuracy: 0.9962 - val_loss: 0.0118\n",
            "Epoch 221/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9893 - loss: 0.0231 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 222/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0231 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 223/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9893 - loss: 0.0231 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 224/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0231 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 225/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0230 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 226/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0230 - val_binary_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 227/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9893 - loss: 0.0230 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 228/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0230 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 229/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0230 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 230/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 231/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 232/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 233/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 234/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0116\n",
            "Epoch 235/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0229 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 236/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0228 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 237/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9893 - loss: 0.0228 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 238/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9893 - loss: 0.0228 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 239/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9895 - loss: 0.0228 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 240/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9895 - loss: 0.0228 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 241/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 242/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0115\n",
            "Epoch 243/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 244/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 245/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 246/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 0.9895 - loss: 0.0227 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 247/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 248/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 249/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 250/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 251/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 252/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9895 - loss: 0.0226 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 253/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 0.9895 - loss: 0.0225 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 254/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9895 - loss: 0.0225 - val_binary_accuracy: 0.9962 - val_loss: 0.0114\n",
            "Epoch 255/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9895 - loss: 0.0225 - val_binary_accuracy: 0.9962 - val_loss: 0.0113\n",
            "Epoch 256/256\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9895 - loss: 0.0225 - val_binary_accuracy: 0.9962 - val_loss: 0.0113\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9924 - loss: 0.0132 \n",
            "Accuracy: 99.62%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# تنظیم seed برای بازتولیدپذیری\n",
        "seed_value = 10\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Maghaleh/Group/Optimization/New/Tehran.csv')  # جایگزین کنید با مسیر فایل شما\n",
        "\n",
        "# تقسیم داده‌ها به ورودی‌ها (X) و خروجی‌ها (y)\n",
        "X = data.iloc[:,[0,1,2]].values  # سه ستون ورودی\n",
        "y = data.iloc[:, -1].values   # ستون خروجی\n",
        "\n",
        "# تقسیم داده‌ها به مجموعه آموزش و آزمون\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed_value)\n",
        "\n",
        "# استانداردسازی داده‌ها\n",
        "clf_scaler = StandardScaler()\n",
        "X_train = clf_scaler.fit_transform(X)\n",
        "X_test = clf_scaler.transform(X_test)\n",
        "\n",
        "# ساخت مدل شبکه عصبی\n",
        "clf_model = Sequential()\n",
        "clf_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # لایه مخفی اول\n",
        "clf_model.add(Dense(256, activation='relu'))\n",
        "clf_model.add(Dense(128, activation='tanh'))\n",
        "clf_model.add(Dense(1, activation='sigmoid'))  # لایه خروجی\n",
        "\n",
        "# کامپایل کردن مدل\n",
        "clf_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "# آموزش مدل\n",
        "clf_model.fit(X_train, y, epochs=256, batch_size=256, validation_data=(X_test, y_test))\n",
        "\n",
        "# ارزیابی مدل\n",
        "loss, accuracy = clf_model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_UmE-tys6-F",
        "outputId": "e04283e9-0106-4ead-f590-396c238ffd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 4000\n",
            "Class 0 count: 775 (19.38%)\n",
            "Class 1 count: 3225 (80.62%)\n"
          ]
        }
      ],
      "source": [
        "class_counts = np.bincount(y)\n",
        "class_distribution = class_counts / len(y) * 100\n",
        "\n",
        "print(f'Total samples: {len(y)}')\n",
        "print(f'Class 0 count: {class_counts[0]} ({class_distribution[0]:.2f}%)')\n",
        "print(f'Class 1 count: {class_counts[1]} ({class_distribution[1]:.2f}%)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6A-wmkVlhet",
        "outputId": "0ce5a865-9a4f-4e0e-8232-2fd3bbed0223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Confusion Matrix:\n",
            "[[168   2]\n",
            " [  1 629]]\n",
            "F1 Score: 0.9976\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "# پیش‌بینی‌های مدل روی داده‌های آزمون\n",
        "y_pred = clf_model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # تبدیل احتمالات به کلاس‌های باینری (0 یا 1)\n",
        "\n",
        "# محاسبه ماتریس سردرگمی\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# محاسبه امتیاز F1\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXFhzQGNHWQu"
      },
      "outputs": [],
      "source": [
        "data =data[data['Failed'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4dHkUjRtIrxv",
        "outputId": "c569fd93-ff41-427c-d3d0-58e268194bbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Number of PV panels  Electrolyzer Capacity (kW)  Tank Volume    LLP(%)  \\\n",
              "1                      35                           8    23.046916  0.001513   \n",
              "3                      49                          17     9.413105  0.001516   \n",
              "7                      36                          10    21.990629  0.001505   \n",
              "11                     36                          14    27.380621  0.001498   \n",
              "13                     46                          18    28.713742  0.001500   \n",
              "...                   ...                         ...          ...       ...   \n",
              "3986                   47                          10    15.233797  0.001511   \n",
              "3987                   47                          13    17.812670  0.001506   \n",
              "3988                   35                          14    24.446839  0.001501   \n",
              "3989                   46                          18    16.670154  0.001510   \n",
              "3993                   50                          15    18.879836  0.001506   \n",
              "\n",
              "      Energy Efficiency (%)      LCOE  Failed  \n",
              "1                  7.767714  1.899161       0  \n",
              "3                  5.536736  1.364577       0  \n",
              "7                  7.595303  1.865258       0  \n",
              "11                 7.630046  2.245150       0  \n",
              "13                 5.962778  2.433589       0  \n",
              "...                     ...       ...     ...  \n",
              "3986               5.792844  1.530044       0  \n",
              "3987               5.810810  1.736106       0  \n",
              "3988               7.832886  2.093050       0  \n",
              "3989               5.921385  1.784188       0  \n",
              "3993               5.463192  1.823861       0  \n",
              "\n",
              "[775 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae983564-da20-43ad-852e-5b53bf2d1ca2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of PV panels</th>\n",
              "      <th>Electrolyzer Capacity (kW)</th>\n",
              "      <th>Tank Volume</th>\n",
              "      <th>LLP(%)</th>\n",
              "      <th>Energy Efficiency (%)</th>\n",
              "      <th>LCOE</th>\n",
              "      <th>Failed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>23.046916</td>\n",
              "      <td>0.001513</td>\n",
              "      <td>7.767714</td>\n",
              "      <td>1.899161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>9.413105</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>5.536736</td>\n",
              "      <td>1.364577</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>36</td>\n",
              "      <td>10</td>\n",
              "      <td>21.990629</td>\n",
              "      <td>0.001505</td>\n",
              "      <td>7.595303</td>\n",
              "      <td>1.865258</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>36</td>\n",
              "      <td>14</td>\n",
              "      <td>27.380621</td>\n",
              "      <td>0.001498</td>\n",
              "      <td>7.630046</td>\n",
              "      <td>2.245150</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>46</td>\n",
              "      <td>18</td>\n",
              "      <td>28.713742</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>5.962778</td>\n",
              "      <td>2.433589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3986</th>\n",
              "      <td>47</td>\n",
              "      <td>10</td>\n",
              "      <td>15.233797</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>5.792844</td>\n",
              "      <td>1.530044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3987</th>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>17.812670</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>5.810810</td>\n",
              "      <td>1.736106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3988</th>\n",
              "      <td>35</td>\n",
              "      <td>14</td>\n",
              "      <td>24.446839</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>7.832886</td>\n",
              "      <td>2.093050</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3989</th>\n",
              "      <td>46</td>\n",
              "      <td>18</td>\n",
              "      <td>16.670154</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>5.921385</td>\n",
              "      <td>1.784188</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3993</th>\n",
              "      <td>50</td>\n",
              "      <td>15</td>\n",
              "      <td>18.879836</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>5.463192</td>\n",
              "      <td>1.823861</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>775 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae983564-da20-43ad-852e-5b53bf2d1ca2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae983564-da20-43ad-852e-5b53bf2d1ca2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae983564-da20-43ad-852e-5b53bf2d1ca2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-129dcdf9-b465-415b-b2f4-16a9c713ef2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-129dcdf9-b465-415b-b2f4-16a9c713ef2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-129dcdf9-b465-415b-b2f4-16a9c713ef2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5bb336e7-e9cd-4c4c-94bb-b57f86935fa3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5bb336e7-e9cd-4c4c-94bb-b57f86935fa3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 775,\n  \"fields\": [\n    {\n      \"column\": \"Number of PV panels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 30,\n        \"max\": 53,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          33,\n          47,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Electrolyzer Capacity (kW)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 6,\n        \"max\": 21,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          17,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tank Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.1427662831813645,\n        \"min\": 6.110262773,\n        \"max\": 29.98009846,\n        \"num_unique_values\": 775,\n        \"samples\": [\n          23.55358584,\n          19.942263,\n          21.10413743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LLP(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.011245818517652e-06,\n        \"min\": 0.001491406,\n        \"max\": 0.001517983,\n        \"num_unique_values\": 759,\n        \"samples\": [\n          0.001510247,\n          0.001508911,\n          0.001510828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Energy Efficiency (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0113723996135662,\n        \"min\": 5.113308962,\n        \"max\": 9.048043763,\n        \"num_unique_values\": 775,\n        \"samples\": [\n          5.473457749,\n          7.788927056,\n          6.070043695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LCOE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3391680153772196,\n        \"min\": 1.152500871,\n        \"max\": 2.485510391,\n        \"num_unique_values\": 775,\n        \"samples\": [\n          2.173836634,\n          1.740298681,\n          1.886864213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Failed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLqcU5ahnDXE",
        "outputId": "febe4213-1797-41ad-cb1b-85bf9ad01e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 21.7934 - r2_score: -32.5870 - val_loss: 18.3003 - val_r2_score: -25.7534\n",
            "Epoch 2/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.2551 - r2_score: -25.0653 - val_loss: 14.1950 - val_r2_score: -19.1763\n",
            "Epoch 3/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13.2204 - r2_score: -18.4516 - val_loss: 10.5120 - val_r2_score: -13.3882\n",
            "Epoch 4/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.6323 - r2_score: -12.6759 - val_loss: 7.2882 - val_r2_score: -8.5376\n",
            "Epoch 5/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.5494 - r2_score: -7.9152 - val_loss: 4.6550 - val_r2_score: -4.9586\n",
            "Epoch 6/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1124 - r2_score: -4.4934 - val_loss: 2.7628 - val_r2_score: -2.8856\n",
            "Epoch 7/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4542 - r2_score: -2.5757 - val_loss: 1.6535 - val_r2_score: -2.0211\n",
            "Epoch 8/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5673 - r2_score: -1.7908 - val_loss: 1.1747 - val_r2_score: -1.5826\n",
            "Epoch 9/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2441 - r2_score: -1.4066 - val_loss: 1.0502 - val_r2_score: -1.1414\n",
            "Epoch 10/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1856 - r2_score: -1.0639 - val_loss: 1.0338 - val_r2_score: -0.8374\n",
            "Epoch 11/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1637 - r2_score: -0.8424 - val_loss: 1.0043 - val_r2_score: -0.7787\n",
            "Epoch 12/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0945 - r2_score: -0.7693 - val_loss: 0.9510 - val_r2_score: -0.7796\n",
            "Epoch 13/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9971 - r2_score: -0.6986 - val_loss: 0.9069 - val_r2_score: -0.6944\n",
            "Epoch 14/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9192 - r2_score: -0.5753 - val_loss: 0.8938 - val_r2_score: -0.5837\n",
            "Epoch 15/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8829 - r2_score: -0.4762 - val_loss: 0.9011 - val_r2_score: -0.5239\n",
            "Epoch 16/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8738 - r2_score: -0.4400 - val_loss: 0.9031 - val_r2_score: -0.4979\n",
            "Epoch 17/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8648 - r2_score: -0.4231 - val_loss: 0.8851 - val_r2_score: -0.4611\n",
            "Epoch 18/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.8423 - r2_score: -0.3826 - val_loss: 0.8513 - val_r2_score: -0.4090\n",
            "Epoch 19/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8106 - r2_score: -0.3245 - val_loss: 0.8144 - val_r2_score: -0.3609\n",
            "Epoch 20/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7802 - r2_score: -0.2725 - val_loss: 0.7826 - val_r2_score: -0.3221\n",
            "Epoch 21/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7558 - r2_score: -0.2328 - val_loss: 0.7579 - val_r2_score: -0.2851\n",
            "Epoch 22/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7362 - r2_score: -0.1979 - val_loss: 0.7385 - val_r2_score: -0.2482\n",
            "Epoch 23/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7187 - r2_score: -0.1645 - val_loss: 0.7230 - val_r2_score: -0.2159\n",
            "Epoch 24/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7020 - r2_score: -0.1342 - val_loss: 0.7103 - val_r2_score: -0.1900\n",
            "Epoch 25/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6862 - r2_score: -0.1072 - val_loss: 0.6993 - val_r2_score: -0.1680\n",
            "Epoch 26/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6716 - r2_score: -0.0823 - val_loss: 0.6888 - val_r2_score: -0.1478\n",
            "Epoch 27/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6578 - r2_score: -0.0588 - val_loss: 0.6775 - val_r2_score: -0.1274\n",
            "Epoch 28/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6442 - r2_score: -0.0360 - val_loss: 0.6649 - val_r2_score: -0.1052\n",
            "Epoch 29/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6305 - r2_score: -0.0130 - val_loss: 0.6508 - val_r2_score: -0.0806\n",
            "Epoch 30/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6165 - r2_score: 0.0105 - val_loss: 0.6363 - val_r2_score: -0.0552\n",
            "Epoch 31/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6026 - r2_score: 0.0337 - val_loss: 0.6220 - val_r2_score: -0.0306\n",
            "Epoch 32/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5891 - r2_score: 0.0564 - val_loss: 0.6085 - val_r2_score: -0.0073\n",
            "Epoch 33/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5760 - r2_score: 0.0785 - val_loss: 0.5956 - val_r2_score: 0.0150\n",
            "Epoch 34/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5632 - r2_score: 0.1000 - val_loss: 0.5833 - val_r2_score: 0.0368\n",
            "Epoch 35/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5507 - r2_score: 0.1212 - val_loss: 0.5712 - val_r2_score: 0.0586\n",
            "Epoch 36/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5384 - r2_score: 0.1422 - val_loss: 0.5591 - val_r2_score: 0.0806\n",
            "Epoch 37/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5262 - r2_score: 0.1630 - val_loss: 0.5469 - val_r2_score: 0.1026\n",
            "Epoch 38/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5140 - r2_score: 0.1836 - val_loss: 0.5346 - val_r2_score: 0.1246\n",
            "Epoch 39/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5020 - r2_score: 0.2040 - val_loss: 0.5223 - val_r2_score: 0.1463\n",
            "Epoch 40/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4900 - r2_score: 0.2241 - val_loss: 0.5099 - val_r2_score: 0.1678\n",
            "Epoch 41/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4781 - r2_score: 0.2440 - val_loss: 0.4978 - val_r2_score: 0.1890\n",
            "Epoch 42/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4664 - r2_score: 0.2636 - val_loss: 0.4858 - val_r2_score: 0.2100\n",
            "Epoch 43/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4548 - r2_score: 0.2830 - val_loss: 0.4741 - val_r2_score: 0.2306\n",
            "Epoch 44/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4434 - r2_score: 0.3021 - val_loss: 0.4625 - val_r2_score: 0.2507\n",
            "Epoch 45/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4321 - r2_score: 0.3210 - val_loss: 0.4511 - val_r2_score: 0.2707\n",
            "Epoch 46/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4210 - r2_score: 0.3396 - val_loss: 0.4397 - val_r2_score: 0.2905\n",
            "Epoch 47/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4099 - r2_score: 0.3581 - val_loss: 0.4284 - val_r2_score: 0.3101\n",
            "Epoch 48/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3990 - r2_score: 0.3764 - val_loss: 0.4171 - val_r2_score: 0.3297\n",
            "Epoch 49/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3881 - r2_score: 0.3945 - val_loss: 0.4059 - val_r2_score: 0.3491\n",
            "Epoch 50/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3774 - r2_score: 0.4124 - val_loss: 0.3948 - val_r2_score: 0.3684\n",
            "Epoch 51/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3668 - r2_score: 0.4300 - val_loss: 0.3838 - val_r2_score: 0.3875\n",
            "Epoch 52/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3564 - r2_score: 0.4475 - val_loss: 0.3729 - val_r2_score: 0.4064\n",
            "Epoch 53/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3461 - r2_score: 0.4647 - val_loss: 0.3621 - val_r2_score: 0.4252\n",
            "Epoch 54/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3359 - r2_score: 0.4816 - val_loss: 0.3514 - val_r2_score: 0.4437\n",
            "Epoch 55/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3259 - r2_score: 0.4983 - val_loss: 0.3409 - val_r2_score: 0.4620\n",
            "Epoch 56/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3160 - r2_score: 0.5147 - val_loss: 0.3305 - val_r2_score: 0.4799\n",
            "Epoch 57/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3063 - r2_score: 0.5308 - val_loss: 0.3203 - val_r2_score: 0.4975\n",
            "Epoch 58/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2968 - r2_score: 0.5466 - val_loss: 0.3103 - val_r2_score: 0.5148\n",
            "Epoch 59/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2875 - r2_score: 0.5621 - val_loss: 0.3005 - val_r2_score: 0.5318\n",
            "Epoch 60/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2784 - r2_score: 0.5773 - val_loss: 0.2909 - val_r2_score: 0.5483\n",
            "Epoch 61/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2694 - r2_score: 0.5921 - val_loss: 0.2815 - val_r2_score: 0.5645\n",
            "Epoch 62/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2606 - r2_score: 0.6066 - val_loss: 0.2722 - val_r2_score: 0.5804\n",
            "Epoch 63/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2521 - r2_score: 0.6208 - val_loss: 0.2632 - val_r2_score: 0.5959\n",
            "Epoch 64/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2437 - r2_score: 0.6345 - val_loss: 0.2545 - val_r2_score: 0.6109\n",
            "Epoch 65/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2356 - r2_score: 0.6480 - val_loss: 0.2460 - val_r2_score: 0.6255\n",
            "Epoch 66/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2276 - r2_score: 0.6611 - val_loss: 0.2377 - val_r2_score: 0.6398\n",
            "Epoch 67/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2199 - r2_score: 0.6738 - val_loss: 0.2296 - val_r2_score: 0.6537\n",
            "Epoch 68/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2124 - r2_score: 0.6862 - val_loss: 0.2216 - val_r2_score: 0.6672\n",
            "Epoch 69/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2050 - r2_score: 0.6983 - val_loss: 0.2139 - val_r2_score: 0.6803\n",
            "Epoch 70/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1979 - r2_score: 0.7100 - val_loss: 0.2065 - val_r2_score: 0.6930\n",
            "Epoch 71/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1909 - r2_score: 0.7214 - val_loss: 0.1992 - val_r2_score: 0.7053\n",
            "Epoch 72/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1841 - r2_score: 0.7325 - val_loss: 0.1922 - val_r2_score: 0.7172\n",
            "Epoch 73/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1775 - r2_score: 0.7433 - val_loss: 0.1853 - val_r2_score: 0.7288\n",
            "Epoch 74/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1711 - r2_score: 0.7537 - val_loss: 0.1786 - val_r2_score: 0.7400\n",
            "Epoch 75/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1649 - r2_score: 0.7637 - val_loss: 0.1722 - val_r2_score: 0.7507\n",
            "Epoch 76/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1589 - r2_score: 0.7734 - val_loss: 0.1659 - val_r2_score: 0.7612\n",
            "Epoch 77/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1531 - r2_score: 0.7828 - val_loss: 0.1598 - val_r2_score: 0.7713\n",
            "Epoch 78/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1475 - r2_score: 0.7919 - val_loss: 0.1539 - val_r2_score: 0.7811\n",
            "Epoch 79/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1420 - r2_score: 0.8006 - val_loss: 0.1482 - val_r2_score: 0.7905\n",
            "Epoch 80/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1368 - r2_score: 0.8090 - val_loss: 0.1427 - val_r2_score: 0.7996\n",
            "Epoch 81/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1316 - r2_score: 0.8171 - val_loss: 0.1373 - val_r2_score: 0.8084\n",
            "Epoch 82/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1267 - r2_score: 0.8250 - val_loss: 0.1321 - val_r2_score: 0.8168\n",
            "Epoch 83/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1219 - r2_score: 0.8326 - val_loss: 0.1271 - val_r2_score: 0.8250\n",
            "Epoch 84/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1172 - r2_score: 0.8399 - val_loss: 0.1222 - val_r2_score: 0.8328\n",
            "Epoch 85/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1128 - r2_score: 0.8469 - val_loss: 0.1176 - val_r2_score: 0.8403\n",
            "Epoch 86/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1084 - r2_score: 0.8537 - val_loss: 0.1131 - val_r2_score: 0.8475\n",
            "Epoch 87/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1043 - r2_score: 0.8602 - val_loss: 0.1087 - val_r2_score: 0.8544\n",
            "Epoch 88/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1003 - r2_score: 0.8664 - val_loss: 0.1046 - val_r2_score: 0.8609\n",
            "Epoch 89/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0964 - r2_score: 0.8723 - val_loss: 0.1006 - val_r2_score: 0.8672\n",
            "Epoch 90/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0926 - r2_score: 0.8780 - val_loss: 0.0967 - val_r2_score: 0.8732\n",
            "Epoch 91/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0891 - r2_score: 0.8835 - val_loss: 0.0930 - val_r2_score: 0.8789\n",
            "Epoch 92/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0856 - r2_score: 0.8887 - val_loss: 0.0894 - val_r2_score: 0.8844\n",
            "Epoch 93/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0822 - r2_score: 0.8937 - val_loss: 0.0860 - val_r2_score: 0.8897\n",
            "Epoch 94/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0790 - r2_score: 0.8985 - val_loss: 0.0827 - val_r2_score: 0.8948\n",
            "Epoch 95/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0759 - r2_score: 0.9031 - val_loss: 0.0795 - val_r2_score: 0.8996\n",
            "Epoch 96/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0729 - r2_score: 0.9075 - val_loss: 0.0764 - val_r2_score: 0.9042\n",
            "Epoch 97/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0700 - r2_score: 0.9118 - val_loss: 0.0734 - val_r2_score: 0.9086\n",
            "Epoch 98/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0672 - r2_score: 0.9158 - val_loss: 0.0705 - val_r2_score: 0.9129\n",
            "Epoch 99/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0646 - r2_score: 0.9196 - val_loss: 0.0677 - val_r2_score: 0.9169\n",
            "Epoch 100/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0620 - r2_score: 0.9233 - val_loss: 0.0650 - val_r2_score: 0.9208\n",
            "Epoch 101/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0595 - r2_score: 0.9268 - val_loss: 0.0624 - val_r2_score: 0.9245\n",
            "Epoch 102/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0571 - r2_score: 0.9302 - val_loss: 0.0599 - val_r2_score: 0.9281\n",
            "Epoch 103/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0547 - r2_score: 0.9334 - val_loss: 0.0575 - val_r2_score: 0.9314\n",
            "Epoch 104/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0525 - r2_score: 0.9365 - val_loss: 0.0552 - val_r2_score: 0.9346\n",
            "Epoch 105/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0504 - r2_score: 0.9394 - val_loss: 0.0530 - val_r2_score: 0.9377\n",
            "Epoch 106/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0483 - r2_score: 0.9421 - val_loss: 0.0508 - val_r2_score: 0.9406\n",
            "Epoch 107/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0463 - r2_score: 0.9448 - val_loss: 0.0488 - val_r2_score: 0.9434\n",
            "Epoch 108/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0444 - r2_score: 0.9473 - val_loss: 0.0468 - val_r2_score: 0.9460\n",
            "Epoch 109/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0426 - r2_score: 0.9497 - val_loss: 0.0449 - val_r2_score: 0.9485\n",
            "Epoch 110/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0408 - r2_score: 0.9520 - val_loss: 0.0430 - val_r2_score: 0.9509\n",
            "Epoch 111/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0391 - r2_score: 0.9541 - val_loss: 0.0412 - val_r2_score: 0.9531\n",
            "Epoch 112/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0375 - r2_score: 0.9562 - val_loss: 0.0395 - val_r2_score: 0.9553\n",
            "Epoch 113/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0359 - r2_score: 0.9582 - val_loss: 0.0379 - val_r2_score: 0.9573\n",
            "Epoch 114/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0344 - r2_score: 0.9600 - val_loss: 0.0363 - val_r2_score: 0.9592\n",
            "Epoch 115/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0330 - r2_score: 0.9618 - val_loss: 0.0348 - val_r2_score: 0.9610\n",
            "Epoch 116/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0316 - r2_score: 0.9634 - val_loss: 0.0334 - val_r2_score: 0.9628\n",
            "Epoch 117/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0303 - r2_score: 0.9650 - val_loss: 0.0320 - val_r2_score: 0.9644\n",
            "Epoch 118/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0290 - r2_score: 0.9665 - val_loss: 0.0307 - val_r2_score: 0.9660\n",
            "Epoch 119/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0278 - r2_score: 0.9680 - val_loss: 0.0294 - val_r2_score: 0.9674\n",
            "Epoch 120/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0266 - r2_score: 0.9693 - val_loss: 0.0282 - val_r2_score: 0.9688\n",
            "Epoch 121/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0255 - r2_score: 0.9706 - val_loss: 0.0270 - val_r2_score: 0.9701\n",
            "Epoch 122/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0245 - r2_score: 0.9718 - val_loss: 0.0259 - val_r2_score: 0.9713\n",
            "Epoch 123/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0234 - r2_score: 0.9729 - val_loss: 0.0248 - val_r2_score: 0.9725\n",
            "Epoch 124/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0225 - r2_score: 0.9740 - val_loss: 0.0238 - val_r2_score: 0.9736\n",
            "Epoch 125/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0215 - r2_score: 0.9751 - val_loss: 0.0228 - val_r2_score: 0.9746\n",
            "Epoch 126/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0206 - r2_score: 0.9760 - val_loss: 0.0219 - val_r2_score: 0.9756\n",
            "Epoch 127/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0198 - r2_score: 0.9770 - val_loss: 0.0210 - val_r2_score: 0.9765\n",
            "Epoch 128/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0190 - r2_score: 0.9778 - val_loss: 0.0201 - val_r2_score: 0.9774\n",
            "Epoch 129/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0182 - r2_score: 0.9787 - val_loss: 0.0193 - val_r2_score: 0.9782\n",
            "Epoch 130/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0174 - r2_score: 0.9795 - val_loss: 0.0185 - val_r2_score: 0.9790\n",
            "Epoch 131/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0167 - r2_score: 0.9802 - val_loss: 0.0178 - val_r2_score: 0.9798\n",
            "Epoch 132/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0160 - r2_score: 0.9809 - val_loss: 0.0171 - val_r2_score: 0.9805\n",
            "Epoch 133/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0154 - r2_score: 0.9816 - val_loss: 0.0164 - val_r2_score: 0.9812\n",
            "Epoch 134/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0147 - r2_score: 0.9822 - val_loss: 0.0157 - val_r2_score: 0.9818\n",
            "Epoch 135/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0141 - r2_score: 0.9829 - val_loss: 0.0151 - val_r2_score: 0.9824\n",
            "Epoch 136/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0136 - r2_score: 0.9834 - val_loss: 0.0145 - val_r2_score: 0.9830\n",
            "Epoch 137/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0130 - r2_score: 0.9840 - val_loss: 0.0139 - val_r2_score: 0.9835\n",
            "Epoch 138/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0125 - r2_score: 0.9845 - val_loss: 0.0134 - val_r2_score: 0.9841\n",
            "Epoch 139/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0120 - r2_score: 0.9850 - val_loss: 0.0128 - val_r2_score: 0.9846\n",
            "Epoch 140/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - r2_score: 0.9855 - val_loss: 0.0123 - val_r2_score: 0.9850\n",
            "Epoch 141/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0111 - r2_score: 0.9860 - val_loss: 0.0119 - val_r2_score: 0.9855\n",
            "Epoch 142/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0106 - r2_score: 0.9864 - val_loss: 0.0114 - val_r2_score: 0.9859\n",
            "Epoch 143/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0102 - r2_score: 0.9868 - val_loss: 0.0110 - val_r2_score: 0.9863\n",
            "Epoch 144/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0098 - r2_score: 0.9872 - val_loss: 0.0106 - val_r2_score: 0.9867\n",
            "Epoch 145/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0094 - r2_score: 0.9876 - val_loss: 0.0102 - val_r2_score: 0.9871\n",
            "Epoch 146/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0091 - r2_score: 0.9880 - val_loss: 0.0098 - val_r2_score: 0.9874\n",
            "Epoch 147/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - r2_score: 0.9883 - val_loss: 0.0094 - val_r2_score: 0.9878\n",
            "Epoch 148/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0084 - r2_score: 0.9886 - val_loss: 0.0091 - val_r2_score: 0.9881\n",
            "Epoch 149/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0081 - r2_score: 0.9890 - val_loss: 0.0087 - val_r2_score: 0.9884\n",
            "Epoch 150/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0078 - r2_score: 0.9893 - val_loss: 0.0084 - val_r2_score: 0.9887\n",
            "Epoch 151/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0075 - r2_score: 0.9896 - val_loss: 0.0081 - val_r2_score: 0.9890\n",
            "Epoch 152/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0073 - r2_score: 0.9898 - val_loss: 0.0079 - val_r2_score: 0.9893\n",
            "Epoch 153/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0070 - r2_score: 0.9901 - val_loss: 0.0076 - val_r2_score: 0.9895\n",
            "Epoch 154/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - r2_score: 0.9904 - val_loss: 0.0073 - val_r2_score: 0.9898\n",
            "Epoch 155/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - r2_score: 0.9906 - val_loss: 0.0071 - val_r2_score: 0.9900\n",
            "Epoch 156/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - r2_score: 0.9909 - val_loss: 0.0068 - val_r2_score: 0.9903\n",
            "Epoch 157/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0061 - r2_score: 0.9911 - val_loss: 0.0066 - val_r2_score: 0.9905\n",
            "Epoch 158/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0059 - r2_score: 0.9913 - val_loss: 0.0064 - val_r2_score: 0.9907\n",
            "Epoch 159/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - r2_score: 0.9915 - val_loss: 0.0062 - val_r2_score: 0.9909\n",
            "Epoch 160/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0055 - r2_score: 0.9917 - val_loss: 0.0060 - val_r2_score: 0.9911\n",
            "Epoch 161/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0054 - r2_score: 0.9919 - val_loss: 0.0058 - val_r2_score: 0.9913\n",
            "Epoch 162/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052 - r2_score: 0.9921 - val_loss: 0.0056 - val_r2_score: 0.9915\n",
            "Epoch 163/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0050 - r2_score: 0.9923 - val_loss: 0.0055 - val_r2_score: 0.9916\n",
            "Epoch 164/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0049 - r2_score: 0.9924 - val_loss: 0.0053 - val_r2_score: 0.9918\n",
            "Epoch 165/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - r2_score: 0.9926 - val_loss: 0.0052 - val_r2_score: 0.9920\n",
            "Epoch 166/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - r2_score: 0.9927 - val_loss: 0.0050 - val_r2_score: 0.9921\n",
            "Epoch 167/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - r2_score: 0.9929 - val_loss: 0.0049 - val_r2_score: 0.9923\n",
            "Epoch 168/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - r2_score: 0.9930 - val_loss: 0.0047 - val_r2_score: 0.9924\n",
            "Epoch 169/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0042 - r2_score: 0.9932 - val_loss: 0.0046 - val_r2_score: 0.9925\n",
            "Epoch 170/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0041 - r2_score: 0.9933 - val_loss: 0.0045 - val_r2_score: 0.9927\n",
            "Epoch 171/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - r2_score: 0.9934 - val_loss: 0.0044 - val_r2_score: 0.9928\n",
            "Epoch 172/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039 - r2_score: 0.9935 - val_loss: 0.0043 - val_r2_score: 0.9929\n",
            "Epoch 173/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0038 - r2_score: 0.9937 - val_loss: 0.0042 - val_r2_score: 0.9930\n",
            "Epoch 174/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - r2_score: 0.9938 - val_loss: 0.0040 - val_r2_score: 0.9931\n",
            "Epoch 175/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036 - r2_score: 0.9939 - val_loss: 0.0039 - val_r2_score: 0.9932\n",
            "Epoch 176/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036 - r2_score: 0.9940 - val_loss: 0.0039 - val_r2_score: 0.9933\n",
            "Epoch 177/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035 - r2_score: 0.9941 - val_loss: 0.0038 - val_r2_score: 0.9934\n",
            "Epoch 178/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - r2_score: 0.9942 - val_loss: 0.0037 - val_r2_score: 0.9935\n",
            "Epoch 179/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - r2_score: 0.9943 - val_loss: 0.0036 - val_r2_score: 0.9936\n",
            "Epoch 180/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0033 - r2_score: 0.9943 - val_loss: 0.0035 - val_r2_score: 0.9937\n",
            "Epoch 181/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032 - r2_score: 0.9944 - val_loss: 0.0034 - val_r2_score: 0.9937\n",
            "Epoch 182/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0031 - r2_score: 0.9945 - val_loss: 0.0034 - val_r2_score: 0.9938\n",
            "Epoch 183/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - r2_score: 0.9946 - val_loss: 0.0033 - val_r2_score: 0.9939\n",
            "Epoch 184/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0030 - r2_score: 0.9947 - val_loss: 0.0032 - val_r2_score: 0.9939\n",
            "Epoch 185/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0029 - r2_score: 0.9947 - val_loss: 0.0032 - val_r2_score: 0.9940\n",
            "Epoch 186/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0029 - r2_score: 0.9948 - val_loss: 0.0031 - val_r2_score: 0.9941\n",
            "Epoch 187/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0028 - r2_score: 0.9949 - val_loss: 0.0030 - val_r2_score: 0.9941\n",
            "Epoch 188/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0028 - r2_score: 0.9949 - val_loss: 0.0030 - val_r2_score: 0.9942\n",
            "Epoch 189/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0027 - r2_score: 0.9950 - val_loss: 0.0029 - val_r2_score: 0.9942\n",
            "Epoch 190/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0027 - r2_score: 0.9950 - val_loss: 0.0029 - val_r2_score: 0.9943\n",
            "Epoch 191/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0026 - r2_score: 0.9951 - val_loss: 0.0028 - val_r2_score: 0.9944\n",
            "Epoch 192/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0026 - r2_score: 0.9951 - val_loss: 0.0028 - val_r2_score: 0.9944\n",
            "Epoch 193/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0026 - r2_score: 0.9952 - val_loss: 0.0027 - val_r2_score: 0.9944\n",
            "Epoch 194/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0025 - r2_score: 0.9952 - val_loss: 0.0027 - val_r2_score: 0.9945\n",
            "Epoch 195/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0025 - r2_score: 0.9953 - val_loss: 0.0026 - val_r2_score: 0.9945\n",
            "Epoch 196/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - r2_score: 0.9953 - val_loss: 0.0026 - val_r2_score: 0.9946\n",
            "Epoch 197/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0024 - r2_score: 0.9954 - val_loss: 0.0025 - val_r2_score: 0.9946\n",
            "Epoch 198/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - r2_score: 0.9954 - val_loss: 0.0025 - val_r2_score: 0.9947\n",
            "Epoch 199/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0023 - r2_score: 0.9955 - val_loss: 0.0025 - val_r2_score: 0.9947\n",
            "Epoch 200/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0023 - r2_score: 0.9955 - val_loss: 0.0024 - val_r2_score: 0.9947\n",
            "Epoch 201/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0023 - r2_score: 0.9956 - val_loss: 0.0024 - val_r2_score: 0.9948\n",
            "Epoch 202/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0022 - r2_score: 0.9956 - val_loss: 0.0024 - val_r2_score: 0.9948\n",
            "Epoch 203/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0022 - r2_score: 0.9956 - val_loss: 0.0023 - val_r2_score: 0.9949\n",
            "Epoch 204/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - r2_score: 0.9957 - val_loss: 0.0023 - val_r2_score: 0.9949\n",
            "Epoch 205/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0021 - r2_score: 0.9957 - val_loss: 0.0023 - val_r2_score: 0.9949\n",
            "Epoch 206/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0021 - r2_score: 0.9957 - val_loss: 0.0022 - val_r2_score: 0.9950\n",
            "Epoch 207/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0021 - r2_score: 0.9958 - val_loss: 0.0022 - val_r2_score: 0.9950\n",
            "Epoch 208/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0021 - r2_score: 0.9958 - val_loss: 0.0022 - val_r2_score: 0.9950\n",
            "Epoch 209/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0020 - r2_score: 0.9958 - val_loss: 0.0021 - val_r2_score: 0.9950\n",
            "Epoch 210/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - r2_score: 0.9959 - val_loss: 0.0021 - val_r2_score: 0.9951\n",
            "Epoch 211/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - r2_score: 0.9959 - val_loss: 0.0021 - val_r2_score: 0.9951\n",
            "Epoch 212/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - r2_score: 0.9959 - val_loss: 0.0020 - val_r2_score: 0.9951\n",
            "Epoch 213/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - r2_score: 0.9960 - val_loss: 0.0020 - val_r2_score: 0.9952\n",
            "Epoch 214/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - r2_score: 0.9960 - val_loss: 0.0020 - val_r2_score: 0.9952\n",
            "Epoch 215/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - r2_score: 0.9960 - val_loss: 0.0020 - val_r2_score: 0.9952\n",
            "Epoch 216/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - r2_score: 0.9960 - val_loss: 0.0019 - val_r2_score: 0.9952\n",
            "Epoch 217/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - r2_score: 0.9961 - val_loss: 0.0019 - val_r2_score: 0.9953\n",
            "Epoch 218/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0018 - r2_score: 0.9961 - val_loss: 0.0019 - val_r2_score: 0.9953\n",
            "Epoch 219/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - r2_score: 0.9961 - val_loss: 0.0019 - val_r2_score: 0.9953\n",
            "Epoch 220/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0018 - r2_score: 0.9961 - val_loss: 0.0019 - val_r2_score: 0.9953\n",
            "Epoch 221/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0018 - r2_score: 0.9962 - val_loss: 0.0018 - val_r2_score: 0.9954\n",
            "Epoch 222/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - r2_score: 0.9962 - val_loss: 0.0018 - val_r2_score: 0.9954\n",
            "Epoch 223/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - r2_score: 0.9962 - val_loss: 0.0018 - val_r2_score: 0.9954\n",
            "Epoch 224/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - r2_score: 0.9962 - val_loss: 0.0018 - val_r2_score: 0.9954\n",
            "Epoch 225/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - r2_score: 0.9963 - val_loss: 0.0018 - val_r2_score: 0.9955\n",
            "Epoch 226/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0017 - r2_score: 0.9963 - val_loss: 0.0017 - val_r2_score: 0.9955\n",
            "Epoch 227/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0017 - r2_score: 0.9963 - val_loss: 0.0017 - val_r2_score: 0.9955\n",
            "Epoch 228/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0017 - r2_score: 0.9963 - val_loss: 0.0017 - val_r2_score: 0.9955\n",
            "Epoch 229/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0016 - r2_score: 0.9964 - val_loss: 0.0017 - val_r2_score: 0.9956\n",
            "Epoch 230/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0016 - r2_score: 0.9964 - val_loss: 0.0017 - val_r2_score: 0.9956\n",
            "Epoch 231/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0016 - r2_score: 0.9964 - val_loss: 0.0016 - val_r2_score: 0.9956\n",
            "Epoch 232/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0016 - r2_score: 0.9964 - val_loss: 0.0016 - val_r2_score: 0.9956\n",
            "Epoch 233/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - r2_score: 0.9964 - val_loss: 0.0016 - val_r2_score: 0.9956\n",
            "Epoch 234/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - r2_score: 0.9965 - val_loss: 0.0016 - val_r2_score: 0.9957\n",
            "Epoch 235/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - r2_score: 0.9965 - val_loss: 0.0016 - val_r2_score: 0.9957\n",
            "Epoch 236/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0015 - r2_score: 0.9965 - val_loss: 0.0016 - val_r2_score: 0.9957\n",
            "Epoch 237/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - r2_score: 0.9965 - val_loss: 0.0015 - val_r2_score: 0.9957\n",
            "Epoch 238/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - r2_score: 0.9965 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 239/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0015 - r2_score: 0.9966 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 240/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - r2_score: 0.9966 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 241/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - r2_score: 0.9966 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 242/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - r2_score: 0.9966 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 243/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - r2_score: 0.9966 - val_loss: 0.0015 - val_r2_score: 0.9958\n",
            "Epoch 244/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - r2_score: 0.9966 - val_loss: 0.0014 - val_r2_score: 0.9959\n",
            "Epoch 245/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9959\n",
            "Epoch 246/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9959\n",
            "Epoch 247/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9959\n",
            "Epoch 248/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9959\n",
            "Epoch 249/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9960\n",
            "Epoch 250/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - r2_score: 0.9967 - val_loss: 0.0014 - val_r2_score: 0.9960\n",
            "Epoch 251/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9960\n",
            "Epoch 252/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9960\n",
            "Epoch 253/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9960\n",
            "Epoch 254/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9961\n",
            "Epoch 255/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9961\n",
            "Epoch 256/256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013 - r2_score: 0.9968 - val_loss: 0.0013 - val_r2_score: 0.9961\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "R^2 Score: 0.9961\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "\n",
        "# تنظیم seed برای بازتولیدپذیری\n",
        "seed_value = 10\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "\n",
        "\n",
        "# تقسیم داده‌ها به ورودی‌ها (X) و خروجی‌ها (y)\n",
        "X = data.iloc[:,[0,1,2]].values  # ستون‌های ورودی (می‌توانید تغییر دهید)\n",
        "y = data.iloc[:, [4,5]].values   # ستون هدف (تارگت) که باید مقدار پیوسته باشد\n",
        "\n",
        "# تقسیم داده‌ها به مجموعه آموزش و آزمون\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed_value)\n",
        "\n",
        "# استانداردسازی داده‌ها\n",
        "reg_scaler = StandardScaler()\n",
        "X_train = reg_scaler.fit_transform(X)\n",
        "X_test = reg_scaler.transform(X_test)\n",
        "\n",
        "# ساخت مدل شبکه عصبی برای رگرسیون\n",
        "reg_model = Sequential()\n",
        "reg_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # لایه مخفی اول\n",
        "reg_model.add(Dense(128, activation='elu'))\n",
        "reg_model.add(Dense(2, activation='linear'))  # لایه خروجی با تابع فعال‌سازی خطی\n",
        "\n",
        "# کامپایل کردن مدل\n",
        "reg_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['r2_score'])\n",
        "\n",
        "# آموزش مدل\n",
        "reg_model.fit(X_train, y, epochs=256, batch_size=256, validation_data=(X_test, y_test))\n",
        "\n",
        "# محاسبه R^2\n",
        "y_pred = reg_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R^2 Score: {r2:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKKBdRfb1AU3"
      },
      "outputs": [],
      "source": [
        "# x_testing = [[34,8,11]]\n",
        "# X_testing_scaled = clf_scaler.transform(x_testing)\n",
        "# clf_model.predict(X_testing_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaGsYgRF8qnz"
      },
      "outputs": [],
      "source": [
        "# x_testing = [[34,8,11]]\n",
        "# X_testing_scaled = reg_scaler.transform(x_testing)\n",
        "# reg_model.predict(X_testing_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zx6JanLEmy3"
      },
      "outputs": [],
      "source": [
        "def Cost_function(params):\n",
        "  Number_PV_panels = params[0]\n",
        "  Electrolyzer_Capacity = params[1]\n",
        "  Tank_volume = params[2]\n",
        "\n",
        "\n",
        "  input_param = [[Number_PV_panels,Electrolyzer_Capacity,Tank_volume]]\n",
        "\n",
        "  input_param_scaled_clf = clf_scaler.transform(input_param)\n",
        "  prediction_clf = clf_model.predict(input_param_scaled_clf,verbose = 0)\n",
        "\n",
        "\n",
        "  if (np.array(prediction_clf)>0.5).astype(int).item() == 1:\n",
        "    return 1000\n",
        "\n",
        "  input_param_scaled_reg = reg_scaler.transform(input_param)\n",
        "  prediction_reg = reg_model.predict(input_param_scaled_reg,verbose = 0)\n",
        "\n",
        "  cost = prediction_reg[0,1]/prediction_reg[0,0]\n",
        "\n",
        "  return cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# تابع هدف (مثال: تابع ساده برای بهینه‌سازی)\n",
        "def objective_function(x):\n",
        "    return Cost_function(x)  # مجموع مربع متغیرها\n",
        "\n",
        "# تولید یک راه حل تصادفی جدید با تغییرات کوچک\n",
        "def generate_new_solution(current_solution, bounds):\n",
        "    new_solution = current_solution.copy()\n",
        "    for i in range(len(new_solution)):\n",
        "        # ایجاد یک تغییر کوچک در هر متغیر با توجه به دامنه مشخص‌شده\n",
        "        change = random.uniform(-1, 1) * (bounds[i][1] - bounds[i][0]) * 0.1\n",
        "        new_solution[i] += change\n",
        "        # محدود کردن به دامنه متغیر\n",
        "        new_solution[i] = max(bounds[i][0], min(new_solution[i], bounds[i][1]))\n",
        "    return new_solution\n",
        "\n",
        "# الگوریتم سرمایش تبریدی\n",
        "def simulated_annealing(objective_function, bounds, max_iterations, initial_temp, cooling_rate):\n",
        "    # شروع با راه حل تصادفی اولیه\n",
        "    current_solution = np.array([random.uniform(b[0], b[1]) for b in bounds])\n",
        "    current_value = objective_function(current_solution)\n",
        "\n",
        "    best_solution = current_solution.copy()\n",
        "    best_value = current_value\n",
        "\n",
        "    temperature = initial_temp\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        # تولید راه حل جدید\n",
        "        new_solution = generate_new_solution(current_solution, bounds)\n",
        "        new_value = objective_function(new_solution)\n",
        "\n",
        "        # محاسبه تغییر انرژی\n",
        "        energy_diff = new_value - current_value\n",
        "\n",
        "        # پذیرش راه‌حل جدید بر اساس احتمال یا بهبود مستقیم\n",
        "        if energy_diff < 0 or random.uniform(0, 1) < np.exp(-energy_diff / temperature):\n",
        "            current_solution = new_solution\n",
        "            current_value = new_value\n",
        "\n",
        "        # به‌روز‌رسانی بهترین راه‌حل\n",
        "        if current_value < best_value:\n",
        "            best_solution = current_solution.copy()\n",
        "            best_value = current_value\n",
        "\n",
        "        # کاهش دما\n",
        "        temperature *= cooling_rate\n",
        "\n",
        "        # نمایش وضعیت (اختیاری)\n",
        "        print(f\"Iteration {iteration+1}/{max_iterations}, Best Value: {best_value}, Temperature: {temperature}\")\n",
        "\n",
        "    return best_solution, best_value\n",
        "\n",
        "# پارامترهای الگوریتم\n",
        "bounds = [(1,53), (1, 21.7),(1,30)]  # دامنه برای هر متغیر\n",
        "max_iterations = 1000\n",
        "initial_temp = 1000\n",
        "cooling_rate = 0.97\n",
        "\n",
        "# اجرای الگوریتم سرمایش تبریدی\n",
        "best_solution, best_value = simulated_annealing(objective_function, bounds, max_iterations, initial_temp, cooling_rate)\n",
        "\n",
        "print(f\"Best Solution: {best_solution}, Best Value: {best_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER4q8RVDFxa6",
        "outputId": "fc348926-b09f-4584-b565-c9b23c428f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/1000, Best Value: 1000, Temperature: 970.0\n",
            "Iteration 2/1000, Best Value: 1000, Temperature: 940.9\n",
            "Iteration 3/1000, Best Value: 1000, Temperature: 912.673\n",
            "Iteration 4/1000, Best Value: 1000, Temperature: 885.29281\n",
            "Iteration 5/1000, Best Value: 1000, Temperature: 858.7340257\n",
            "Iteration 6/1000, Best Value: 1000, Temperature: 832.9720049289999\n",
            "Iteration 7/1000, Best Value: 1000, Temperature: 807.9828447811299\n",
            "Iteration 8/1000, Best Value: 1000, Temperature: 783.743359437696\n",
            "Iteration 9/1000, Best Value: 1000, Temperature: 760.2310586545651\n",
            "Iteration 10/1000, Best Value: 1000, Temperature: 737.4241268949281\n",
            "Iteration 11/1000, Best Value: 1000, Temperature: 715.3014030880803\n",
            "Iteration 12/1000, Best Value: 1000, Temperature: 693.8423609954378\n",
            "Iteration 13/1000, Best Value: 1000, Temperature: 673.0270901655747\n",
            "Iteration 14/1000, Best Value: 1000, Temperature: 652.8362774606074\n",
            "Iteration 15/1000, Best Value: 1000, Temperature: 633.2511891367892\n",
            "Iteration 16/1000, Best Value: 1000, Temperature: 614.2536534626855\n",
            "Iteration 17/1000, Best Value: 1000, Temperature: 595.826043858805\n",
            "Iteration 18/1000, Best Value: 1000, Temperature: 577.9512625430408\n",
            "Iteration 19/1000, Best Value: 1000, Temperature: 560.6127246667496\n",
            "Iteration 20/1000, Best Value: 1000, Temperature: 543.7943429267472\n",
            "Iteration 21/1000, Best Value: 1000, Temperature: 527.4805126389448\n",
            "Iteration 22/1000, Best Value: 1000, Temperature: 511.6560972597764\n",
            "Iteration 23/1000, Best Value: 1000, Temperature: 496.3064143419831\n",
            "Iteration 24/1000, Best Value: 1000, Temperature: 481.4172219117236\n",
            "Iteration 25/1000, Best Value: 1000, Temperature: 466.9747052543718\n",
            "Iteration 26/1000, Best Value: 1000, Temperature: 452.9654640967407\n",
            "Iteration 27/1000, Best Value: 1000, Temperature: 439.37650017383845\n",
            "Iteration 28/1000, Best Value: 1000, Temperature: 426.19520516862326\n",
            "Iteration 29/1000, Best Value: 1000, Temperature: 413.40934901356457\n",
            "Iteration 30/1000, Best Value: 1000, Temperature: 401.00706854315763\n",
            "Iteration 31/1000, Best Value: 1000, Temperature: 388.9768564868629\n",
            "Iteration 32/1000, Best Value: 1000, Temperature: 377.307550792257\n",
            "Iteration 33/1000, Best Value: 1000, Temperature: 365.9883242684893\n",
            "Iteration 34/1000, Best Value: 1000, Temperature: 355.0086745404346\n",
            "Iteration 35/1000, Best Value: 1000, Temperature: 344.3584143042215\n",
            "Iteration 36/1000, Best Value: 1000, Temperature: 334.02766187509485\n",
            "Iteration 37/1000, Best Value: 1000, Temperature: 324.006832018842\n",
            "Iteration 38/1000, Best Value: 1000, Temperature: 314.28662705827674\n",
            "Iteration 39/1000, Best Value: 1000, Temperature: 304.8580282465284\n",
            "Iteration 40/1000, Best Value: 1000, Temperature: 295.71228739913255\n",
            "Iteration 41/1000, Best Value: 1000, Temperature: 286.84091877715855\n",
            "Iteration 42/1000, Best Value: 1000, Temperature: 278.2356912138438\n",
            "Iteration 43/1000, Best Value: 1000, Temperature: 269.88862047742845\n",
            "Iteration 44/1000, Best Value: 1000, Temperature: 261.7919618631056\n",
            "Iteration 45/1000, Best Value: 1000, Temperature: 253.93820300721242\n",
            "Iteration 46/1000, Best Value: 1000, Temperature: 246.32005691699604\n",
            "Iteration 47/1000, Best Value: 1000, Temperature: 238.93045520948615\n",
            "Iteration 48/1000, Best Value: 1000, Temperature: 231.76254155320157\n",
            "Iteration 49/1000, Best Value: 1000, Temperature: 224.80966530660552\n",
            "Iteration 50/1000, Best Value: 1000, Temperature: 218.06537534740735\n",
            "Iteration 51/1000, Best Value: 1000, Temperature: 211.52341408698513\n",
            "Iteration 52/1000, Best Value: 1000, Temperature: 205.17771166437558\n",
            "Iteration 53/1000, Best Value: 1000, Temperature: 199.02238031444432\n",
            "Iteration 54/1000, Best Value: 1000, Temperature: 193.051708905011\n",
            "Iteration 55/1000, Best Value: 1000, Temperature: 187.26015763786066\n",
            "Iteration 56/1000, Best Value: 1000, Temperature: 181.64235290872483\n",
            "Iteration 57/1000, Best Value: 1000, Temperature: 176.1930823214631\n",
            "Iteration 58/1000, Best Value: 1000, Temperature: 170.9072898518192\n",
            "Iteration 59/1000, Best Value: 1000, Temperature: 165.78007115626463\n",
            "Iteration 60/1000, Best Value: 1000, Temperature: 160.80666902157668\n",
            "Iteration 61/1000, Best Value: 1000, Temperature: 155.9824689509294\n",
            "Iteration 62/1000, Best Value: 1000, Temperature: 151.3029948824015\n",
            "Iteration 63/1000, Best Value: 1000, Temperature: 146.76390503592944\n",
            "Iteration 64/1000, Best Value: 1000, Temperature: 142.36098788485154\n",
            "Iteration 65/1000, Best Value: 1000, Temperature: 138.09015824830598\n",
            "Iteration 66/1000, Best Value: 1000, Temperature: 133.9474535008568\n",
            "Iteration 67/1000, Best Value: 1000, Temperature: 129.9290298958311\n",
            "Iteration 68/1000, Best Value: 1000, Temperature: 126.03115899895616\n",
            "Iteration 69/1000, Best Value: 1000, Temperature: 122.25022422898748\n",
            "Iteration 70/1000, Best Value: 1000, Temperature: 118.58271750211784\n",
            "Iteration 71/1000, Best Value: 1000, Temperature: 115.02523597705431\n",
            "Iteration 72/1000, Best Value: 1000, Temperature: 111.57447889774268\n",
            "Iteration 73/1000, Best Value: 1000, Temperature: 108.2272445308104\n",
            "Iteration 74/1000, Best Value: 1000, Temperature: 104.98042719488608\n",
            "Iteration 75/1000, Best Value: 1000, Temperature: 101.83101437903949\n",
            "Iteration 76/1000, Best Value: 1000, Temperature: 98.7760839476683\n",
            "Iteration 77/1000, Best Value: 1000, Temperature: 95.81280142923825\n",
            "Iteration 78/1000, Best Value: 1000, Temperature: 92.9384173863611\n",
            "Iteration 79/1000, Best Value: 1000, Temperature: 90.15026486477026\n",
            "Iteration 80/1000, Best Value: 1000, Temperature: 87.44575691882716\n",
            "Iteration 81/1000, Best Value: 1000, Temperature: 84.82238421126235\n",
            "Iteration 82/1000, Best Value: 1000, Temperature: 82.27771268492447\n",
            "Iteration 83/1000, Best Value: 1000, Temperature: 79.80938130437673\n",
            "Iteration 84/1000, Best Value: 1000, Temperature: 77.41509986524542\n",
            "Iteration 85/1000, Best Value: 1000, Temperature: 75.09264686928806\n",
            "Iteration 86/1000, Best Value: 1000, Temperature: 72.83986746320942\n",
            "Iteration 87/1000, Best Value: 1000, Temperature: 70.65467143931313\n",
            "Iteration 88/1000, Best Value: 1000, Temperature: 68.53503129613374\n",
            "Iteration 89/1000, Best Value: 1000, Temperature: 66.47898035724972\n",
            "Iteration 90/1000, Best Value: 1000, Temperature: 64.48461094653223\n",
            "Iteration 91/1000, Best Value: 1000, Temperature: 62.55007261813626\n",
            "Iteration 92/1000, Best Value: 1000, Temperature: 60.673570439592176\n",
            "Iteration 93/1000, Best Value: 1000, Temperature: 58.853363326404406\n",
            "Iteration 94/1000, Best Value: 1000, Temperature: 57.08776242661227\n",
            "Iteration 95/1000, Best Value: 1000, Temperature: 55.375129553813906\n",
            "Iteration 96/1000, Best Value: 1000, Temperature: 53.71387566719949\n",
            "Iteration 97/1000, Best Value: 1000, Temperature: 52.1024593971835\n",
            "Iteration 98/1000, Best Value: 1000, Temperature: 50.539385615267996\n",
            "Iteration 99/1000, Best Value: 1000, Temperature: 49.02320404680995\n",
            "Iteration 100/1000, Best Value: 1000, Temperature: 47.55250792540565\n",
            "Iteration 101/1000, Best Value: 1000, Temperature: 46.12593268764348\n",
            "Iteration 102/1000, Best Value: 1000, Temperature: 44.74215470701417\n",
            "Iteration 103/1000, Best Value: 1000, Temperature: 43.399890065803746\n",
            "Iteration 104/1000, Best Value: 1000, Temperature: 42.097893363829634\n",
            "Iteration 105/1000, Best Value: 1000, Temperature: 40.83495656291474\n",
            "Iteration 106/1000, Best Value: 1000, Temperature: 39.6099078660273\n",
            "Iteration 107/1000, Best Value: 1000, Temperature: 38.42161063004648\n",
            "Iteration 108/1000, Best Value: 1000, Temperature: 37.26896231114508\n",
            "Iteration 109/1000, Best Value: 1000, Temperature: 36.15089344181073\n",
            "Iteration 110/1000, Best Value: 1000, Temperature: 35.06636663855641\n",
            "Iteration 111/1000, Best Value: 1000, Temperature: 34.01437563939972\n",
            "Iteration 112/1000, Best Value: 1000, Temperature: 32.993944370217726\n",
            "Iteration 113/1000, Best Value: 1000, Temperature: 32.00412603911119\n",
            "Iteration 114/1000, Best Value: 1000, Temperature: 31.044002257937855\n",
            "Iteration 115/1000, Best Value: 1000, Temperature: 30.112682190199717\n",
            "Iteration 116/1000, Best Value: 1000, Temperature: 29.209301724493724\n",
            "Iteration 117/1000, Best Value: 1000, Temperature: 28.33302267275891\n",
            "Iteration 118/1000, Best Value: 1000, Temperature: 27.483031992576144\n",
            "Iteration 119/1000, Best Value: 1000, Temperature: 26.65854103279886\n",
            "Iteration 120/1000, Best Value: 1000, Temperature: 25.858784801814892\n",
            "Iteration 121/1000, Best Value: 1000, Temperature: 25.083021257760443\n",
            "Iteration 122/1000, Best Value: 1000, Temperature: 24.33053062002763\n",
            "Iteration 123/1000, Best Value: 1000, Temperature: 23.6006147014268\n",
            "Iteration 124/1000, Best Value: 1000, Temperature: 22.892596260383996\n",
            "Iteration 125/1000, Best Value: 1000, Temperature: 22.205818372572477\n",
            "Iteration 126/1000, Best Value: 1000, Temperature: 21.539643821395302\n",
            "Iteration 127/1000, Best Value: 1000, Temperature: 20.893454506753443\n",
            "Iteration 128/1000, Best Value: 1000, Temperature: 20.26665087155084\n",
            "Iteration 129/1000, Best Value: 1000, Temperature: 19.658651345404316\n",
            "Iteration 130/1000, Best Value: 1000, Temperature: 19.068891805042185\n",
            "Iteration 131/1000, Best Value: 1000, Temperature: 18.49682505089092\n",
            "Iteration 132/1000, Best Value: 1000, Temperature: 17.94192029936419\n",
            "Iteration 133/1000, Best Value: 1000, Temperature: 17.403662690383264\n",
            "Iteration 134/1000, Best Value: 1000, Temperature: 16.881552809671767\n",
            "Iteration 135/1000, Best Value: 1000, Temperature: 16.375106225381614\n",
            "Iteration 136/1000, Best Value: 1000, Temperature: 15.883853038620165\n",
            "Iteration 137/1000, Best Value: 1000, Temperature: 15.40733744746156\n",
            "Iteration 138/1000, Best Value: 1000, Temperature: 14.945117324037712\n",
            "Iteration 139/1000, Best Value: 1000, Temperature: 14.496763804316581\n",
            "Iteration 140/1000, Best Value: 1000, Temperature: 14.061860890187083\n",
            "Iteration 141/1000, Best Value: 1000, Temperature: 13.64000506348147\n",
            "Iteration 142/1000, Best Value: 1000, Temperature: 13.230804911577025\n",
            "Iteration 143/1000, Best Value: 1000, Temperature: 12.833880764229713\n",
            "Iteration 144/1000, Best Value: 1000, Temperature: 12.448864341302821\n",
            "Iteration 145/1000, Best Value: 1000, Temperature: 12.075398411063736\n",
            "Iteration 146/1000, Best Value: 1000, Temperature: 11.713136458731823\n",
            "Iteration 147/1000, Best Value: 1000, Temperature: 11.361742364969867\n",
            "Iteration 148/1000, Best Value: 1000, Temperature: 11.020890094020771\n",
            "Iteration 149/1000, Best Value: 1000, Temperature: 10.690263391200148\n",
            "Iteration 150/1000, Best Value: 1000, Temperature: 10.369555489464142\n",
            "Iteration 151/1000, Best Value: 1000, Temperature: 10.058468824780217\n",
            "Iteration 152/1000, Best Value: 1000, Temperature: 9.756714760036811\n",
            "Iteration 153/1000, Best Value: 1000, Temperature: 9.464013317235706\n",
            "Iteration 154/1000, Best Value: 1000, Temperature: 9.180092917718634\n",
            "Iteration 155/1000, Best Value: 1000, Temperature: 8.904690130187074\n",
            "Iteration 156/1000, Best Value: 1000, Temperature: 8.637549426281462\n",
            "Iteration 157/1000, Best Value: 1000, Temperature: 8.378422943493018\n",
            "Iteration 158/1000, Best Value: 1000, Temperature: 8.127070255188226\n",
            "Iteration 159/1000, Best Value: 1000, Temperature: 7.883258147532579\n",
            "Iteration 160/1000, Best Value: 1000, Temperature: 7.646760403106601\n",
            "Iteration 161/1000, Best Value: 1000, Temperature: 7.417357591013403\n",
            "Iteration 162/1000, Best Value: 1000, Temperature: 7.194836863283\n",
            "Iteration 163/1000, Best Value: 1000, Temperature: 6.97899175738451\n",
            "Iteration 164/1000, Best Value: 1000, Temperature: 6.769622004662975\n",
            "Iteration 165/1000, Best Value: 1000, Temperature: 6.566533344523085\n",
            "Iteration 166/1000, Best Value: 1000, Temperature: 6.369537344187393\n",
            "Iteration 167/1000, Best Value: 1000, Temperature: 6.178451223861771\n",
            "Iteration 168/1000, Best Value: 1000, Temperature: 5.993097687145918\n",
            "Iteration 169/1000, Best Value: 1000, Temperature: 5.81330475653154\n",
            "Iteration 170/1000, Best Value: 1000, Temperature: 5.638905613835594\n",
            "Iteration 171/1000, Best Value: 1000, Temperature: 5.469738445420526\n",
            "Iteration 172/1000, Best Value: 1000, Temperature: 5.30564629205791\n",
            "Iteration 173/1000, Best Value: 1000, Temperature: 5.146476903296172\n",
            "Iteration 174/1000, Best Value: 1000, Temperature: 4.992082596197287\n",
            "Iteration 175/1000, Best Value: 0.2763461768627167, Temperature: 4.842320118311369\n",
            "Iteration 176/1000, Best Value: 0.2763461768627167, Temperature: 4.697050514762028\n",
            "Iteration 177/1000, Best Value: 0.2763461768627167, Temperature: 4.556138999319167\n",
            "Iteration 178/1000, Best Value: 0.2763461768627167, Temperature: 4.419454829339592\n",
            "Iteration 179/1000, Best Value: 0.2763461768627167, Temperature: 4.286871184459404\n",
            "Iteration 180/1000, Best Value: 0.2763461768627167, Temperature: 4.158265048925622\n",
            "Iteration 181/1000, Best Value: 0.25740036368370056, Temperature: 4.033517097457853\n",
            "Iteration 182/1000, Best Value: 0.25740036368370056, Temperature: 3.9125115845341174\n",
            "Iteration 183/1000, Best Value: 0.25740036368370056, Temperature: 3.795136236998094\n",
            "Iteration 184/1000, Best Value: 0.24547959864139557, Temperature: 3.681282149888151\n",
            "Iteration 185/1000, Best Value: 0.24547959864139557, Temperature: 3.5708436853915067\n",
            "Iteration 186/1000, Best Value: 0.24547959864139557, Temperature: 3.4637183748297615\n",
            "Iteration 187/1000, Best Value: 0.2365364283323288, Temperature: 3.3598068235848686\n",
            "Iteration 188/1000, Best Value: 0.2365364283323288, Temperature: 3.2590126188773225\n",
            "Iteration 189/1000, Best Value: 0.2365364283323288, Temperature: 3.1612422403110028\n",
            "Iteration 190/1000, Best Value: 0.2365364283323288, Temperature: 3.0664049731016725\n",
            "Iteration 191/1000, Best Value: 0.2365364283323288, Temperature: 2.9744128239086223\n",
            "Iteration 192/1000, Best Value: 0.2365364283323288, Temperature: 2.8851804391913634\n",
            "Iteration 193/1000, Best Value: 0.2365364283323288, Temperature: 2.7986250260156225\n",
            "Iteration 194/1000, Best Value: 0.2365364283323288, Temperature: 2.7146662752351536\n",
            "Iteration 195/1000, Best Value: 0.2365364283323288, Temperature: 2.6332262869780987\n",
            "Iteration 196/1000, Best Value: 0.2365364283323288, Temperature: 2.5542294983687555\n",
            "Iteration 197/1000, Best Value: 0.2365364283323288, Temperature: 2.4776026134176927\n",
            "Iteration 198/1000, Best Value: 0.2365364283323288, Temperature: 2.403274535015162\n",
            "Iteration 199/1000, Best Value: 0.2365364283323288, Temperature: 2.3311762989647073\n",
            "Iteration 200/1000, Best Value: 0.2365364283323288, Temperature: 2.261241009995766\n",
            "Iteration 201/1000, Best Value: 0.2365364283323288, Temperature: 2.193403779695893\n",
            "Iteration 202/1000, Best Value: 0.2365364283323288, Temperature: 2.1276016663050163\n",
            "Iteration 203/1000, Best Value: 0.2365364283323288, Temperature: 2.0637736163158658\n",
            "Iteration 204/1000, Best Value: 0.2365364283323288, Temperature: 2.0018604078263897\n",
            "Iteration 205/1000, Best Value: 0.2365364283323288, Temperature: 1.941804595591598\n",
            "Iteration 206/1000, Best Value: 0.2365364283323288, Temperature: 1.88355045772385\n",
            "Iteration 207/1000, Best Value: 0.2365364283323288, Temperature: 1.8270439439921344\n",
            "Iteration 208/1000, Best Value: 0.2365364283323288, Temperature: 1.7722326256723704\n",
            "Iteration 209/1000, Best Value: 0.2365364283323288, Temperature: 1.7190656469021992\n",
            "Iteration 210/1000, Best Value: 0.2365364283323288, Temperature: 1.6674936774951332\n",
            "Iteration 211/1000, Best Value: 0.2365364283323288, Temperature: 1.6174688671702793\n",
            "Iteration 212/1000, Best Value: 0.2365364283323288, Temperature: 1.5689448011551708\n",
            "Iteration 213/1000, Best Value: 0.2365364283323288, Temperature: 1.5218764571205157\n",
            "Iteration 214/1000, Best Value: 0.2365364283323288, Temperature: 1.4762201634069\n",
            "Iteration 215/1000, Best Value: 0.2365364283323288, Temperature: 1.431933558504693\n",
            "Iteration 216/1000, Best Value: 0.2365364283323288, Temperature: 1.3889755517495523\n",
            "Iteration 217/1000, Best Value: 0.2365364283323288, Temperature: 1.3473062851970656\n",
            "Iteration 218/1000, Best Value: 0.2365364283323288, Temperature: 1.3068870966411537\n",
            "Iteration 219/1000, Best Value: 0.2365364283323288, Temperature: 1.267680483741919\n",
            "Iteration 220/1000, Best Value: 0.2365364283323288, Temperature: 1.2296500692296615\n",
            "Iteration 221/1000, Best Value: 0.2365364283323288, Temperature: 1.1927605671527717\n",
            "Iteration 222/1000, Best Value: 0.2365364283323288, Temperature: 1.1569777501381886\n",
            "Iteration 223/1000, Best Value: 0.2365364283323288, Temperature: 1.122268417634043\n",
            "Iteration 224/1000, Best Value: 0.2365364283323288, Temperature: 1.0886003651050216\n",
            "Iteration 225/1000, Best Value: 0.2365364283323288, Temperature: 1.0559423541518709\n",
            "Iteration 226/1000, Best Value: 0.2365364283323288, Temperature: 1.0242640835273147\n",
            "Iteration 227/1000, Best Value: 0.2365364283323288, Temperature: 0.9935361610214952\n",
            "Iteration 228/1000, Best Value: 0.2365364283323288, Temperature: 0.9637300761908504\n",
            "Iteration 229/1000, Best Value: 0.2365364283323288, Temperature: 0.9348181739051249\n",
            "Iteration 230/1000, Best Value: 0.2365364283323288, Temperature: 0.9067736286879711\n",
            "Iteration 231/1000, Best Value: 0.2365364283323288, Temperature: 0.8795704198273319\n",
            "Iteration 232/1000, Best Value: 0.2365364283323288, Temperature: 0.8531833072325119\n",
            "Iteration 233/1000, Best Value: 0.2365364283323288, Temperature: 0.8275878080155366\n",
            "Iteration 234/1000, Best Value: 0.2365364283323288, Temperature: 0.8027601737750705\n",
            "Iteration 235/1000, Best Value: 0.2365364283323288, Temperature: 0.7786773685618184\n",
            "Iteration 236/1000, Best Value: 0.2365364283323288, Temperature: 0.7553170475049638\n",
            "Iteration 237/1000, Best Value: 0.2365364283323288, Temperature: 0.7326575360798149\n",
            "Iteration 238/1000, Best Value: 0.2365364283323288, Temperature: 0.7106778099974204\n",
            "Iteration 239/1000, Best Value: 0.2365364283323288, Temperature: 0.6893574756974977\n",
            "Iteration 240/1000, Best Value: 0.2365364283323288, Temperature: 0.6686767514265728\n",
            "Iteration 241/1000, Best Value: 0.2365364283323288, Temperature: 0.6486164488837756\n",
            "Iteration 242/1000, Best Value: 0.2365364283323288, Temperature: 0.6291579554172623\n",
            "Iteration 243/1000, Best Value: 0.2365364283323288, Temperature: 0.6102832167547444\n",
            "Iteration 244/1000, Best Value: 0.2365364283323288, Temperature: 0.5919747202521021\n",
            "Iteration 245/1000, Best Value: 0.2365364283323288, Temperature: 0.574215478644539\n",
            "Iteration 246/1000, Best Value: 0.2365364283323288, Temperature: 0.5569890142852029\n",
            "Iteration 247/1000, Best Value: 0.2365364283323288, Temperature: 0.5402793438566468\n",
            "Iteration 248/1000, Best Value: 0.2365364283323288, Temperature: 0.5240709635409474\n",
            "Iteration 249/1000, Best Value: 0.2365364283323288, Temperature: 0.5083488346347189\n",
            "Iteration 250/1000, Best Value: 0.2365364283323288, Temperature: 0.4930983695956773\n",
            "Iteration 251/1000, Best Value: 0.2365364283323288, Temperature: 0.478305418507807\n",
            "Iteration 252/1000, Best Value: 0.2365364283323288, Temperature: 0.4639562559525728\n",
            "Iteration 253/1000, Best Value: 0.2365364283323288, Temperature: 0.4500375682739956\n",
            "Iteration 254/1000, Best Value: 0.2365364283323288, Temperature: 0.43653644122577573\n",
            "Iteration 255/1000, Best Value: 0.2365364283323288, Temperature: 0.42344034798900243\n",
            "Iteration 256/1000, Best Value: 0.2365364283323288, Temperature: 0.41073713754933233\n",
            "Iteration 257/1000, Best Value: 0.2365364283323288, Temperature: 0.39841502342285234\n",
            "Iteration 258/1000, Best Value: 0.2365364283323288, Temperature: 0.38646257272016676\n",
            "Iteration 259/1000, Best Value: 0.2365364283323288, Temperature: 0.3748686955385617\n",
            "Iteration 260/1000, Best Value: 0.2365364283323288, Temperature: 0.36362263467240485\n",
            "Iteration 261/1000, Best Value: 0.22584813833236694, Temperature: 0.3527139556322327\n",
            "Iteration 262/1000, Best Value: 0.21771815419197083, Temperature: 0.3421325369632657\n",
            "Iteration 263/1000, Best Value: 0.19872096180915833, Temperature: 0.3318685608543677\n",
            "Iteration 264/1000, Best Value: 0.19872096180915833, Temperature: 0.32191250402873667\n",
            "Iteration 265/1000, Best Value: 0.19872096180915833, Temperature: 0.31225512890787455\n",
            "Iteration 266/1000, Best Value: 0.19872096180915833, Temperature: 0.3028874750406383\n",
            "Iteration 267/1000, Best Value: 0.19872096180915833, Temperature: 0.29380085078941914\n",
            "Iteration 268/1000, Best Value: 0.19872096180915833, Temperature: 0.28498682526573654\n",
            "Iteration 269/1000, Best Value: 0.19872096180915833, Temperature: 0.2764372205077644\n",
            "Iteration 270/1000, Best Value: 0.19872096180915833, Temperature: 0.26814410389253146\n",
            "Iteration 271/1000, Best Value: 0.19872096180915833, Temperature: 0.2600997807757555\n",
            "Iteration 272/1000, Best Value: 0.19872096180915833, Temperature: 0.25229678735248284\n",
            "Iteration 273/1000, Best Value: 0.19872096180915833, Temperature: 0.24472788373190835\n",
            "Iteration 274/1000, Best Value: 0.19872096180915833, Temperature: 0.2373860472199511\n",
            "Iteration 275/1000, Best Value: 0.19872096180915833, Temperature: 0.23026446580335255\n",
            "Iteration 276/1000, Best Value: 0.19872096180915833, Temperature: 0.22335653182925197\n",
            "Iteration 277/1000, Best Value: 0.19872096180915833, Temperature: 0.2166558358743744\n",
            "Iteration 278/1000, Best Value: 0.19872096180915833, Temperature: 0.21015616079814317\n",
            "Iteration 279/1000, Best Value: 0.19872096180915833, Temperature: 0.20385147597419886\n",
            "Iteration 280/1000, Best Value: 0.19872096180915833, Temperature: 0.1977359316949729\n",
            "Iteration 281/1000, Best Value: 0.19872096180915833, Temperature: 0.1918038537441237\n",
            "Iteration 282/1000, Best Value: 0.19872096180915833, Temperature: 0.18604973813179998\n",
            "Iteration 283/1000, Best Value: 0.19872096180915833, Temperature: 0.18046824598784597\n",
            "Iteration 284/1000, Best Value: 0.19872096180915833, Temperature: 0.1750541986082106\n",
            "Iteration 285/1000, Best Value: 0.19872096180915833, Temperature: 0.16980257264996426\n",
            "Iteration 286/1000, Best Value: 0.19872096180915833, Temperature: 0.16470849547046532\n",
            "Iteration 287/1000, Best Value: 0.19872096180915833, Temperature: 0.15976724060635136\n",
            "Iteration 288/1000, Best Value: 0.19872096180915833, Temperature: 0.15497422338816083\n",
            "Iteration 289/1000, Best Value: 0.19872096180915833, Temperature: 0.150324996686516\n",
            "Iteration 290/1000, Best Value: 0.19872096180915833, Temperature: 0.1458152467859205\n",
            "Iteration 291/1000, Best Value: 0.19872096180915833, Temperature: 0.1414407893823429\n",
            "Iteration 292/1000, Best Value: 0.19872096180915833, Temperature: 0.1371975657008726\n",
            "Iteration 293/1000, Best Value: 0.19872096180915833, Temperature: 0.13308163872984644\n",
            "Iteration 294/1000, Best Value: 0.19872096180915833, Temperature: 0.12908918956795104\n",
            "Iteration 295/1000, Best Value: 0.19872096180915833, Temperature: 0.1252165138809125\n",
            "Iteration 296/1000, Best Value: 0.19872096180915833, Temperature: 0.12146001846448513\n",
            "Iteration 297/1000, Best Value: 0.19872096180915833, Temperature: 0.11781621791055058\n",
            "Iteration 298/1000, Best Value: 0.19872096180915833, Temperature: 0.11428173137323407\n",
            "Iteration 299/1000, Best Value: 0.19872096180915833, Temperature: 0.11085327943203704\n",
            "Iteration 300/1000, Best Value: 0.19872096180915833, Temperature: 0.10752768104907592\n",
            "Iteration 301/1000, Best Value: 0.19872096180915833, Temperature: 0.10430185061760364\n",
            "Iteration 302/1000, Best Value: 0.19872096180915833, Temperature: 0.10117279509907552\n",
            "Iteration 303/1000, Best Value: 0.19872096180915833, Temperature: 0.09813761124610325\n",
            "Iteration 304/1000, Best Value: 0.19872096180915833, Temperature: 0.09519348290872015\n",
            "Iteration 305/1000, Best Value: 0.19872096180915833, Temperature: 0.09233767842145854\n",
            "Iteration 306/1000, Best Value: 0.19872096180915833, Temperature: 0.08956754806881478\n",
            "Iteration 307/1000, Best Value: 0.19872096180915833, Temperature: 0.08688052162675033\n",
            "Iteration 308/1000, Best Value: 0.19872096180915833, Temperature: 0.08427410597794782\n",
            "Iteration 309/1000, Best Value: 0.19872096180915833, Temperature: 0.08174588279860938\n",
            "Iteration 310/1000, Best Value: 0.19872096180915833, Temperature: 0.0792935063146511\n",
            "Iteration 311/1000, Best Value: 0.19872096180915833, Temperature: 0.07691470112521157\n",
            "Iteration 312/1000, Best Value: 0.19872096180915833, Temperature: 0.07460726009145521\n",
            "Iteration 313/1000, Best Value: 0.19872096180915833, Temperature: 0.07236904228871155\n",
            "Iteration 314/1000, Best Value: 0.19872096180915833, Temperature: 0.0701979710200502\n",
            "Iteration 315/1000, Best Value: 0.19872096180915833, Temperature: 0.06809203188944869\n",
            "Iteration 316/1000, Best Value: 0.19872096180915833, Temperature: 0.06604927093276523\n",
            "Iteration 317/1000, Best Value: 0.19872096180915833, Temperature: 0.06406779280478228\n",
            "Iteration 318/1000, Best Value: 0.19872096180915833, Temperature: 0.06214575902063881\n",
            "Iteration 319/1000, Best Value: 0.19872096180915833, Temperature: 0.06028138625001964\n",
            "Iteration 320/1000, Best Value: 0.19872096180915833, Temperature: 0.05847294466251905\n",
            "Iteration 321/1000, Best Value: 0.19872096180915833, Temperature: 0.05671875632264348\n",
            "Iteration 322/1000, Best Value: 0.19872096180915833, Temperature: 0.05501719363296417\n",
            "Iteration 323/1000, Best Value: 0.19872096180915833, Temperature: 0.05336667782397524\n",
            "Iteration 324/1000, Best Value: 0.19872096180915833, Temperature: 0.051765677489255986\n",
            "Iteration 325/1000, Best Value: 0.19872096180915833, Temperature: 0.050212707164578305\n",
            "Iteration 326/1000, Best Value: 0.19872096180915833, Temperature: 0.04870632594964095\n",
            "Iteration 327/1000, Best Value: 0.19872096180915833, Temperature: 0.04724513617115172\n",
            "Iteration 328/1000, Best Value: 0.19872096180915833, Temperature: 0.04582778208601716\n",
            "Iteration 329/1000, Best Value: 0.19872096180915833, Temperature: 0.04445294862343665\n",
            "Iteration 330/1000, Best Value: 0.19872096180915833, Temperature: 0.04311936016473355\n",
            "Iteration 331/1000, Best Value: 0.19872096180915833, Temperature: 0.041825779359791544\n",
            "Iteration 332/1000, Best Value: 0.19872096180915833, Temperature: 0.0405710059789978\n",
            "Iteration 333/1000, Best Value: 0.19872096180915833, Temperature: 0.03935387579962787\n",
            "Iteration 334/1000, Best Value: 0.19872096180915833, Temperature: 0.03817325952563903\n",
            "Iteration 335/1000, Best Value: 0.19872096180915833, Temperature: 0.03702806173986986\n",
            "Iteration 336/1000, Best Value: 0.19872096180915833, Temperature: 0.03591721988767376\n",
            "Iteration 337/1000, Best Value: 0.19872096180915833, Temperature: 0.03483970329104355\n",
            "Iteration 338/1000, Best Value: 0.19872096180915833, Temperature: 0.03379451219231224\n",
            "Iteration 339/1000, Best Value: 0.19872096180915833, Temperature: 0.03278067682654287\n",
            "Iteration 340/1000, Best Value: 0.19872096180915833, Temperature: 0.031797256521746586\n",
            "Iteration 341/1000, Best Value: 0.19872096180915833, Temperature: 0.030843338826094188\n",
            "Iteration 342/1000, Best Value: 0.19872096180915833, Temperature: 0.02991803866131136\n",
            "Iteration 343/1000, Best Value: 0.19872096180915833, Temperature: 0.02902049750147202\n",
            "Iteration 344/1000, Best Value: 0.19872096180915833, Temperature: 0.028149882576427858\n",
            "Iteration 345/1000, Best Value: 0.19872096180915833, Temperature: 0.02730538609913502\n",
            "Iteration 346/1000, Best Value: 0.19872096180915833, Temperature: 0.02648622451616097\n",
            "Iteration 347/1000, Best Value: 0.19872096180915833, Temperature: 0.02569163778067614\n",
            "Iteration 348/1000, Best Value: 0.19872096180915833, Temperature: 0.024920888647255855\n",
            "Iteration 349/1000, Best Value: 0.19872096180915833, Temperature: 0.024173261987838177\n",
            "Iteration 350/1000, Best Value: 0.19872096180915833, Temperature: 0.023448064128203033\n",
            "Iteration 351/1000, Best Value: 0.19872096180915833, Temperature: 0.02274462220435694\n",
            "Iteration 352/1000, Best Value: 0.19872096180915833, Temperature: 0.022062283538226233\n",
            "Iteration 353/1000, Best Value: 0.19872096180915833, Temperature: 0.021400415032079446\n",
            "Iteration 354/1000, Best Value: 0.19872096180915833, Temperature: 0.020758402581117063\n",
            "Iteration 355/1000, Best Value: 0.19872096180915833, Temperature: 0.02013565050368355\n",
            "Iteration 356/1000, Best Value: 0.19872096180915833, Temperature: 0.019531580988573043\n",
            "Iteration 357/1000, Best Value: 0.19872096180915833, Temperature: 0.01894563355891585\n",
            "Iteration 358/1000, Best Value: 0.19872096180915833, Temperature: 0.018377264552148376\n",
            "Iteration 359/1000, Best Value: 0.19872096180915833, Temperature: 0.017825946615583926\n",
            "Iteration 360/1000, Best Value: 0.19872096180915833, Temperature: 0.017291168217116407\n",
            "Iteration 361/1000, Best Value: 0.19872096180915833, Temperature: 0.016772433170602914\n",
            "Iteration 362/1000, Best Value: 0.19872096180915833, Temperature: 0.016269260175484825\n",
            "Iteration 363/1000, Best Value: 0.19872096180915833, Temperature: 0.01578118237022028\n",
            "Iteration 364/1000, Best Value: 0.19872096180915833, Temperature: 0.015307746899113671\n",
            "Iteration 365/1000, Best Value: 0.19872096180915833, Temperature: 0.014848514492140261\n",
            "Iteration 366/1000, Best Value: 0.19872096180915833, Temperature: 0.014403059057376053\n",
            "Iteration 367/1000, Best Value: 0.19872096180915833, Temperature: 0.013970967285654771\n",
            "Iteration 368/1000, Best Value: 0.19872096180915833, Temperature: 0.013551838267085128\n",
            "Iteration 369/1000, Best Value: 0.19872096180915833, Temperature: 0.013145283119072574\n",
            "Iteration 370/1000, Best Value: 0.19872096180915833, Temperature: 0.012750924625500397\n",
            "Iteration 371/1000, Best Value: 0.19872096180915833, Temperature: 0.012368396886735385\n",
            "Iteration 372/1000, Best Value: 0.19872096180915833, Temperature: 0.011997344980133324\n",
            "Iteration 373/1000, Best Value: 0.19872096180915833, Temperature: 0.011637424630729323\n",
            "Iteration 374/1000, Best Value: 0.19872096180915833, Temperature: 0.011288301891807443\n",
            "Iteration 375/1000, Best Value: 0.19872096180915833, Temperature: 0.01094965283505322\n",
            "Iteration 376/1000, Best Value: 0.19872096180915833, Temperature: 0.010621163250001623\n",
            "Iteration 377/1000, Best Value: 0.19872096180915833, Temperature: 0.010302528352501575\n",
            "Iteration 378/1000, Best Value: 0.19872096180915833, Temperature: 0.009993452501926528\n",
            "Iteration 379/1000, Best Value: 0.19872096180915833, Temperature: 0.009693648926868732\n",
            "Iteration 380/1000, Best Value: 0.19872096180915833, Temperature: 0.00940283945906267\n",
            "Iteration 381/1000, Best Value: 0.19872096180915833, Temperature: 0.009120754275290788\n",
            "Iteration 382/1000, Best Value: 0.19872096180915833, Temperature: 0.008847131647032064\n",
            "Iteration 383/1000, Best Value: 0.19872096180915833, Temperature: 0.008581717697621102\n",
            "Iteration 384/1000, Best Value: 0.19872096180915833, Temperature: 0.00832426616669247\n",
            "Iteration 385/1000, Best Value: 0.19872096180915833, Temperature: 0.008074538181691696\n",
            "Iteration 386/1000, Best Value: 0.19872096180915833, Temperature: 0.007832302036240945\n",
            "Iteration 387/1000, Best Value: 0.19872096180915833, Temperature: 0.0075973329751537165\n",
            "Iteration 388/1000, Best Value: 0.19872096180915833, Temperature: 0.007369412985899105\n",
            "Iteration 389/1000, Best Value: 0.19872096180915833, Temperature: 0.007148330596322132\n",
            "Iteration 390/1000, Best Value: 0.19872096180915833, Temperature: 0.006933880678432468\n",
            "Iteration 391/1000, Best Value: 0.19872096180915833, Temperature: 0.006725864258079494\n",
            "Iteration 392/1000, Best Value: 0.19872096180915833, Temperature: 0.006524088330337109\n",
            "Iteration 393/1000, Best Value: 0.19872096180915833, Temperature: 0.006328365680426996\n",
            "Iteration 394/1000, Best Value: 0.19872096180915833, Temperature: 0.006138514710014186\n",
            "Iteration 395/1000, Best Value: 0.19872096180915833, Temperature: 0.00595435926871376\n",
            "Iteration 396/1000, Best Value: 0.19872096180915833, Temperature: 0.005775728490652347\n",
            "Iteration 397/1000, Best Value: 0.19872096180915833, Temperature: 0.0056024566359327765\n",
            "Iteration 398/1000, Best Value: 0.19872096180915833, Temperature: 0.005434382936854793\n",
            "Iteration 399/1000, Best Value: 0.19872096180915833, Temperature: 0.0052713514487491495\n",
            "Iteration 400/1000, Best Value: 0.19872096180915833, Temperature: 0.005113210905286675\n",
            "Iteration 401/1000, Best Value: 0.19872096180915833, Temperature: 0.004959814578128074\n",
            "Iteration 402/1000, Best Value: 0.19872096180915833, Temperature: 0.0048110201407842315\n",
            "Iteration 403/1000, Best Value: 0.19872096180915833, Temperature: 0.004666689536560705\n",
            "Iteration 404/1000, Best Value: 0.19872096180915833, Temperature: 0.004526688850463883\n",
            "Iteration 405/1000, Best Value: 0.19872096180915833, Temperature: 0.004390888184949967\n",
            "Iteration 406/1000, Best Value: 0.19872096180915833, Temperature: 0.004259161539401468\n",
            "Iteration 407/1000, Best Value: 0.19872096180915833, Temperature: 0.004131386693219424\n",
            "Iteration 408/1000, Best Value: 0.19872096180915833, Temperature: 0.004007445092422841\n",
            "Iteration 409/1000, Best Value: 0.19872096180915833, Temperature: 0.003887221739650156\n",
            "Iteration 410/1000, Best Value: 0.19872096180915833, Temperature: 0.0037706050874606514\n",
            "Iteration 411/1000, Best Value: 0.19872096180915833, Temperature: 0.003657486934836832\n",
            "Iteration 412/1000, Best Value: 0.19872096180915833, Temperature: 0.003547762326791727\n",
            "Iteration 413/1000, Best Value: 0.19872096180915833, Temperature: 0.0034413294569879747\n",
            "Iteration 414/1000, Best Value: 0.19872096180915833, Temperature: 0.003338089573278335\n",
            "Iteration 415/1000, Best Value: 0.19872096180915833, Temperature: 0.0032379468860799852\n",
            "Iteration 416/1000, Best Value: 0.19872096180915833, Temperature: 0.0031408084794975854\n",
            "Iteration 417/1000, Best Value: 0.19872096180915833, Temperature: 0.003046584225112658\n",
            "Iteration 418/1000, Best Value: 0.19872096180915833, Temperature: 0.0029551866983592782\n",
            "Iteration 419/1000, Best Value: 0.19872096180915833, Temperature: 0.0028665310974085\n",
            "Iteration 420/1000, Best Value: 0.19872096180915833, Temperature: 0.0027805351644862447\n",
            "Iteration 421/1000, Best Value: 0.19872096180915833, Temperature: 0.0026971191095516572\n",
            "Iteration 422/1000, Best Value: 0.19872096180915833, Temperature: 0.0026162055362651073\n",
            "Iteration 423/1000, Best Value: 0.19872096180915833, Temperature: 0.002537719370177154\n",
            "Iteration 424/1000, Best Value: 0.19872096180915833, Temperature: 0.0024615877890718394\n",
            "Iteration 425/1000, Best Value: 0.19872096180915833, Temperature: 0.002387740155399684\n",
            "Iteration 426/1000, Best Value: 0.19872096180915833, Temperature: 0.0023161079507376934\n",
            "Iteration 427/1000, Best Value: 0.1968868225812912, Temperature: 0.0022466247122155626\n",
            "Iteration 428/1000, Best Value: 0.1968868225812912, Temperature: 0.0021792259708490955\n",
            "Iteration 429/1000, Best Value: 0.1968868225812912, Temperature: 0.0021138491917236228\n",
            "Iteration 430/1000, Best Value: 0.1968868225812912, Temperature: 0.002050433715971914\n",
            "Iteration 431/1000, Best Value: 0.1968868225812912, Temperature: 0.0019889207044927566\n",
            "Iteration 432/1000, Best Value: 0.1968868225812912, Temperature: 0.0019292530833579739\n",
            "Iteration 433/1000, Best Value: 0.1968868225812912, Temperature: 0.0018713754908572346\n",
            "Iteration 434/1000, Best Value: 0.1968868225812912, Temperature: 0.0018152342261315176\n",
            "Iteration 435/1000, Best Value: 0.1968868225812912, Temperature: 0.001760777199347572\n",
            "Iteration 436/1000, Best Value: 0.19423653185367584, Temperature: 0.0017079538833671447\n",
            "Iteration 437/1000, Best Value: 0.19423653185367584, Temperature: 0.0016567152668661303\n",
            "Iteration 438/1000, Best Value: 0.19423653185367584, Temperature: 0.0016070138088601464\n",
            "Iteration 439/1000, Best Value: 0.19423653185367584, Temperature: 0.001558803394594342\n",
            "Iteration 440/1000, Best Value: 0.19423653185367584, Temperature: 0.0015120392927565115\n",
            "Iteration 441/1000, Best Value: 0.19423653185367584, Temperature: 0.0014666781139738162\n",
            "Iteration 442/1000, Best Value: 0.192362979054451, Temperature: 0.0014226777705546017\n",
            "Iteration 443/1000, Best Value: 0.1920006275177002, Temperature: 0.0013799974374379637\n",
            "Iteration 444/1000, Best Value: 0.18248437345027924, Temperature: 0.0013385975143148246\n",
            "Iteration 445/1000, Best Value: 0.18248437345027924, Temperature: 0.0012984395888853799\n",
            "Iteration 446/1000, Best Value: 0.18248437345027924, Temperature: 0.0012594864012188184\n",
            "Iteration 447/1000, Best Value: 0.18248437345027924, Temperature: 0.0012217018091822537\n",
            "Iteration 448/1000, Best Value: 0.18248437345027924, Temperature: 0.0011850507549067862\n",
            "Iteration 449/1000, Best Value: 0.18248437345027924, Temperature: 0.0011494992322595825\n",
            "Iteration 450/1000, Best Value: 0.18248437345027924, Temperature: 0.001115014255291795\n",
            "Iteration 451/1000, Best Value: 0.18248437345027924, Temperature: 0.001081563827633041\n",
            "Iteration 452/1000, Best Value: 0.18248437345027924, Temperature: 0.00104911691280405\n",
            "Iteration 453/1000, Best Value: 0.18248437345027924, Temperature: 0.0010176434054199285\n",
            "Iteration 454/1000, Best Value: 0.18204283714294434, Temperature: 0.0009871141032573305\n",
            "Iteration 455/1000, Best Value: 0.18204283714294434, Temperature: 0.0009575006801596106\n",
            "Iteration 456/1000, Best Value: 0.18204283714294434, Temperature: 0.0009287756597548222\n",
            "Iteration 457/1000, Best Value: 0.18204283714294434, Temperature: 0.0009009123899621776\n",
            "Iteration 458/1000, Best Value: 0.18204283714294434, Temperature: 0.0008738850182633122\n",
            "Iteration 459/1000, Best Value: 0.18204283714294434, Temperature: 0.0008476684677154128\n",
            "Iteration 460/1000, Best Value: 0.18204283714294434, Temperature: 0.0008222384136839505\n",
            "Iteration 461/1000, Best Value: 0.18204283714294434, Temperature: 0.0007975712612734319\n",
            "Iteration 462/1000, Best Value: 0.18204283714294434, Temperature: 0.0007736441234352289\n",
            "Iteration 463/1000, Best Value: 0.18204283714294434, Temperature: 0.000750434799732172\n",
            "Iteration 464/1000, Best Value: 0.18204283714294434, Temperature: 0.0007279217557402068\n",
            "Iteration 465/1000, Best Value: 0.18204283714294434, Temperature: 0.0007060841030680006\n",
            "Iteration 466/1000, Best Value: 0.18204283714294434, Temperature: 0.0006849015799759605\n",
            "Iteration 467/1000, Best Value: 0.18204283714294434, Temperature: 0.0006643545325766817\n",
            "Iteration 468/1000, Best Value: 0.18204283714294434, Temperature: 0.0006444238965993812\n",
            "Iteration 469/1000, Best Value: 0.18204283714294434, Temperature: 0.0006250911797013997\n",
            "Iteration 470/1000, Best Value: 0.18204283714294434, Temperature: 0.0006063384443103577\n",
            "Iteration 471/1000, Best Value: 0.18204283714294434, Temperature: 0.0005881482909810469\n",
            "Iteration 472/1000, Best Value: 0.18204283714294434, Temperature: 0.0005705038422516154\n",
            "Iteration 473/1000, Best Value: 0.18204283714294434, Temperature: 0.000553388726984067\n",
            "Iteration 474/1000, Best Value: 0.18204283714294434, Temperature: 0.000536787065174545\n",
            "Iteration 475/1000, Best Value: 0.18204283714294434, Temperature: 0.0005206834532193086\n",
            "Iteration 476/1000, Best Value: 0.18204283714294434, Temperature: 0.0005050629496227293\n",
            "Iteration 477/1000, Best Value: 0.18204283714294434, Temperature: 0.0004899110611340475\n",
            "Iteration 478/1000, Best Value: 0.18204283714294434, Temperature: 0.000475213729300026\n",
            "Iteration 479/1000, Best Value: 0.18204283714294434, Temperature: 0.00046095731742102524\n",
            "Iteration 480/1000, Best Value: 0.18204283714294434, Temperature: 0.00044712859789839446\n",
            "Iteration 481/1000, Best Value: 0.1787138134241104, Temperature: 0.0004337147399614426\n",
            "Iteration 482/1000, Best Value: 0.1787138134241104, Temperature: 0.0004207032977625993\n",
            "Iteration 483/1000, Best Value: 0.1787138134241104, Temperature: 0.00040808219882972134\n",
            "Iteration 484/1000, Best Value: 0.1787138134241104, Temperature: 0.0003958397328648297\n",
            "Iteration 485/1000, Best Value: 0.1787138134241104, Temperature: 0.0003839645408788848\n",
            "Iteration 486/1000, Best Value: 0.1787138134241104, Temperature: 0.00037244560465251827\n",
            "Iteration 487/1000, Best Value: 0.1787138134241104, Temperature: 0.0003612722365129427\n",
            "Iteration 488/1000, Best Value: 0.1787138134241104, Temperature: 0.0003504340694175544\n",
            "Iteration 489/1000, Best Value: 0.1787138134241104, Temperature: 0.00033992104733502774\n",
            "Iteration 490/1000, Best Value: 0.1787138134241104, Temperature: 0.0003297234159149769\n",
            "Iteration 491/1000, Best Value: 0.1787138134241104, Temperature: 0.0003198317134375276\n",
            "Iteration 492/1000, Best Value: 0.1787138134241104, Temperature: 0.00031023676203440176\n",
            "Iteration 493/1000, Best Value: 0.1787138134241104, Temperature: 0.0003009296591733697\n",
            "Iteration 494/1000, Best Value: 0.1787138134241104, Temperature: 0.0002919017693981686\n",
            "Iteration 495/1000, Best Value: 0.1787138134241104, Temperature: 0.00028314471631622355\n",
            "Iteration 496/1000, Best Value: 0.1787138134241104, Temperature: 0.00027465037482673685\n",
            "Iteration 497/1000, Best Value: 0.1787138134241104, Temperature: 0.0002664108635819347\n",
            "Iteration 498/1000, Best Value: 0.1787138134241104, Temperature: 0.00025841853767447667\n",
            "Iteration 499/1000, Best Value: 0.1787138134241104, Temperature: 0.0002506659815442424\n",
            "Iteration 500/1000, Best Value: 0.1787138134241104, Temperature: 0.0002431460020979151\n",
            "Iteration 501/1000, Best Value: 0.1787138134241104, Temperature: 0.00023585162203497765\n",
            "Iteration 502/1000, Best Value: 0.1787138134241104, Temperature: 0.0002287760733739283\n",
            "Iteration 503/1000, Best Value: 0.1787138134241104, Temperature: 0.00022191279117271046\n",
            "Iteration 504/1000, Best Value: 0.1787138134241104, Temperature: 0.00021525540743752913\n",
            "Iteration 505/1000, Best Value: 0.1787138134241104, Temperature: 0.00020879774521440325\n",
            "Iteration 506/1000, Best Value: 0.1787138134241104, Temperature: 0.00020253381285797114\n",
            "Iteration 507/1000, Best Value: 0.1787138134241104, Temperature: 0.000196457798472232\n",
            "Iteration 508/1000, Best Value: 0.1787138134241104, Temperature: 0.00019056406451806504\n",
            "Iteration 509/1000, Best Value: 0.1787138134241104, Temperature: 0.0001848471425825231\n",
            "Iteration 510/1000, Best Value: 0.1787138134241104, Temperature: 0.0001793017283050474\n",
            "Iteration 511/1000, Best Value: 0.1787138134241104, Temperature: 0.00017392267645589598\n",
            "Iteration 512/1000, Best Value: 0.1787138134241104, Temperature: 0.0001687049961622191\n",
            "Iteration 513/1000, Best Value: 0.1787138134241104, Temperature: 0.00016364384627735252\n",
            "Iteration 514/1000, Best Value: 0.1787138134241104, Temperature: 0.00015873453088903193\n",
            "Iteration 515/1000, Best Value: 0.1787138134241104, Temperature: 0.00015397249496236097\n",
            "Iteration 516/1000, Best Value: 0.1787138134241104, Temperature: 0.00014935332011349012\n",
            "Iteration 517/1000, Best Value: 0.1787138134241104, Temperature: 0.00014487272051008542\n",
            "Iteration 518/1000, Best Value: 0.1787138134241104, Temperature: 0.00014052653889478286\n",
            "Iteration 519/1000, Best Value: 0.1787138134241104, Temperature: 0.00013631074272793937\n",
            "Iteration 520/1000, Best Value: 0.1787138134241104, Temperature: 0.0001322214204461012\n",
            "Iteration 521/1000, Best Value: 0.1787138134241104, Temperature: 0.00012825477783271814\n",
            "Iteration 522/1000, Best Value: 0.1787138134241104, Temperature: 0.0001244071344977366\n",
            "Iteration 523/1000, Best Value: 0.1787138134241104, Temperature: 0.00012067492046280449\n",
            "Iteration 524/1000, Best Value: 0.1787138134241104, Temperature: 0.00011705467284892036\n",
            "Iteration 525/1000, Best Value: 0.1787138134241104, Temperature: 0.00011354303266345275\n",
            "Iteration 526/1000, Best Value: 0.1787138134241104, Temperature: 0.00011013674168354916\n",
            "Iteration 527/1000, Best Value: 0.1787138134241104, Temperature: 0.00010683263943304268\n",
            "Iteration 528/1000, Best Value: 0.1764814257621765, Temperature: 0.0001036276602500514\n",
            "Iteration 529/1000, Best Value: 0.1764814257621765, Temperature: 0.00010051883044254985\n",
            "Iteration 530/1000, Best Value: 0.1764814257621765, Temperature: 9.750326552927335e-05\n",
            "Iteration 531/1000, Best Value: 0.1764814257621765, Temperature: 9.457816756339515e-05\n",
            "Iteration 532/1000, Best Value: 0.1764814257621765, Temperature: 9.17408225364933e-05\n",
            "Iteration 533/1000, Best Value: 0.1764814257621765, Temperature: 8.89885978603985e-05\n",
            "Iteration 534/1000, Best Value: 0.17385372519493103, Temperature: 8.631893992458654e-05\n",
            "Iteration 535/1000, Best Value: 0.17385372519493103, Temperature: 8.372937172684894e-05\n",
            "Iteration 536/1000, Best Value: 0.17385372519493103, Temperature: 8.121749057504347e-05\n",
            "Iteration 537/1000, Best Value: 0.17385372519493103, Temperature: 7.878096585779217e-05\n",
            "Iteration 538/1000, Best Value: 0.17385372519493103, Temperature: 7.64175368820584e-05\n",
            "Iteration 539/1000, Best Value: 0.17385372519493103, Temperature: 7.412501077559666e-05\n",
            "Iteration 540/1000, Best Value: 0.17385372519493103, Temperature: 7.190126045232876e-05\n",
            "Iteration 541/1000, Best Value: 0.17385372519493103, Temperature: 6.97442226387589e-05\n",
            "Iteration 542/1000, Best Value: 0.17385372519493103, Temperature: 6.765189595959613e-05\n",
            "Iteration 543/1000, Best Value: 0.17385372519493103, Temperature: 6.562233908080823e-05\n",
            "Iteration 544/1000, Best Value: 0.17385372519493103, Temperature: 6.365366890838399e-05\n",
            "Iteration 545/1000, Best Value: 0.17385372519493103, Temperature: 6.174405884113247e-05\n",
            "Iteration 546/1000, Best Value: 0.1716681867837906, Temperature: 5.98917370758985e-05\n",
            "Iteration 547/1000, Best Value: 0.1716681867837906, Temperature: 5.809498496362154e-05\n",
            "Iteration 548/1000, Best Value: 0.1716681867837906, Temperature: 5.635213541471289e-05\n",
            "Iteration 549/1000, Best Value: 0.1716681867837906, Temperature: 5.46615713522715e-05\n",
            "Iteration 550/1000, Best Value: 0.1710343062877655, Temperature: 5.3021724211703356e-05\n",
            "Iteration 551/1000, Best Value: 0.1710343062877655, Temperature: 5.143107248535226e-05\n",
            "Iteration 552/1000, Best Value: 0.1710343062877655, Temperature: 4.9888140310791686e-05\n",
            "Iteration 553/1000, Best Value: 0.1710343062877655, Temperature: 4.8391496101467935e-05\n",
            "Iteration 554/1000, Best Value: 0.1710343062877655, Temperature: 4.69397512184239e-05\n",
            "Iteration 555/1000, Best Value: 0.1710343062877655, Temperature: 4.553155868187118e-05\n",
            "Iteration 556/1000, Best Value: 0.170572891831398, Temperature: 4.4165611921415043e-05\n",
            "Iteration 557/1000, Best Value: 0.170572891831398, Temperature: 4.284064356377259e-05\n",
            "Iteration 558/1000, Best Value: 0.170572891831398, Temperature: 4.155542425685941e-05\n",
            "Iteration 559/1000, Best Value: 0.170572891831398, Temperature: 4.030876152915363e-05\n",
            "Iteration 560/1000, Best Value: 0.170572891831398, Temperature: 3.909949868327902e-05\n",
            "Iteration 561/1000, Best Value: 0.170572891831398, Temperature: 3.7926513722780646e-05\n",
            "Iteration 562/1000, Best Value: 0.170572891831398, Temperature: 3.678871831109723e-05\n",
            "Iteration 563/1000, Best Value: 0.170572891831398, Temperature: 3.568505676176431e-05\n",
            "Iteration 564/1000, Best Value: 0.170572891831398, Temperature: 3.461450505891138e-05\n",
            "Iteration 565/1000, Best Value: 0.170572891831398, Temperature: 3.357606990714404e-05\n",
            "Iteration 566/1000, Best Value: 0.170572891831398, Temperature: 3.2568787809929716e-05\n",
            "Iteration 567/1000, Best Value: 0.170572891831398, Temperature: 3.1591724175631824e-05\n",
            "Iteration 568/1000, Best Value: 0.170572891831398, Temperature: 3.064397245036287e-05\n",
            "Iteration 569/1000, Best Value: 0.170572891831398, Temperature: 2.9724653276851982e-05\n",
            "Iteration 570/1000, Best Value: 0.16721594333648682, Temperature: 2.883291367854642e-05\n",
            "Iteration 571/1000, Best Value: 0.16721594333648682, Temperature: 2.7967926268190026e-05\n",
            "Iteration 572/1000, Best Value: 0.16721594333648682, Temperature: 2.7128888480144324e-05\n",
            "Iteration 573/1000, Best Value: 0.16721594333648682, Temperature: 2.6315021825739995e-05\n",
            "Iteration 574/1000, Best Value: 0.16721594333648682, Temperature: 2.5525571170967796e-05\n",
            "Iteration 575/1000, Best Value: 0.16721594333648682, Temperature: 2.475980403583876e-05\n",
            "Iteration 576/1000, Best Value: 0.16721594333648682, Temperature: 2.4017009914763598e-05\n",
            "Iteration 577/1000, Best Value: 0.16721594333648682, Temperature: 2.329649961732069e-05\n",
            "Iteration 578/1000, Best Value: 0.16721594333648682, Temperature: 2.2597604628801068e-05\n",
            "Iteration 579/1000, Best Value: 0.16721594333648682, Temperature: 2.1919676489937034e-05\n",
            "Iteration 580/1000, Best Value: 0.16721594333648682, Temperature: 2.1262086195238922e-05\n",
            "Iteration 581/1000, Best Value: 0.16721594333648682, Temperature: 2.0624223609381755e-05\n",
            "Iteration 582/1000, Best Value: 0.16721594333648682, Temperature: 2.0005496901100303e-05\n",
            "Iteration 583/1000, Best Value: 0.16721594333648682, Temperature: 1.9405331994067293e-05\n",
            "Iteration 584/1000, Best Value: 0.16721594333648682, Temperature: 1.8823172034245274e-05\n",
            "Iteration 585/1000, Best Value: 0.16721594333648682, Temperature: 1.8258476873217916e-05\n",
            "Iteration 586/1000, Best Value: 0.16721594333648682, Temperature: 1.7710722567021378e-05\n",
            "Iteration 587/1000, Best Value: 0.16721594333648682, Temperature: 1.7179400890010735e-05\n",
            "Iteration 588/1000, Best Value: 0.16721594333648682, Temperature: 1.6664018863310414e-05\n",
            "Iteration 589/1000, Best Value: 0.16721594333648682, Temperature: 1.61640982974111e-05\n",
            "Iteration 590/1000, Best Value: 0.16721594333648682, Temperature: 1.5679175348488767e-05\n",
            "Iteration 591/1000, Best Value: 0.16721594333648682, Temperature: 1.5208800088034104e-05\n",
            "Iteration 592/1000, Best Value: 0.16721594333648682, Temperature: 1.475253608539308e-05\n",
            "Iteration 593/1000, Best Value: 0.16721594333648682, Temperature: 1.4309960002831286e-05\n",
            "Iteration 594/1000, Best Value: 0.16721594333648682, Temperature: 1.3880661202746347e-05\n",
            "Iteration 595/1000, Best Value: 0.16721594333648682, Temperature: 1.3464241366663957e-05\n",
            "Iteration 596/1000, Best Value: 0.16721594333648682, Temperature: 1.3060314125664039e-05\n",
            "Iteration 597/1000, Best Value: 0.16721594333648682, Temperature: 1.2668504701894118e-05\n",
            "Iteration 598/1000, Best Value: 0.16721594333648682, Temperature: 1.2288449560837294e-05\n",
            "Iteration 599/1000, Best Value: 0.16721594333648682, Temperature: 1.1919796074012175e-05\n",
            "Iteration 600/1000, Best Value: 0.16721594333648682, Temperature: 1.156220219179181e-05\n",
            "Iteration 601/1000, Best Value: 0.16721594333648682, Temperature: 1.1215336126038055e-05\n",
            "Iteration 602/1000, Best Value: 0.16721594333648682, Temperature: 1.0878876042256913e-05\n",
            "Iteration 603/1000, Best Value: 0.16721594333648682, Temperature: 1.0552509760989205e-05\n",
            "Iteration 604/1000, Best Value: 0.16721594333648682, Temperature: 1.0235934468159529e-05\n",
            "Iteration 605/1000, Best Value: 0.16721594333648682, Temperature: 9.928856434114743e-06\n",
            "Iteration 606/1000, Best Value: 0.16721594333648682, Temperature: 9.630990741091302e-06\n",
            "Iteration 607/1000, Best Value: 0.16721594333648682, Temperature: 9.342061018858562e-06\n",
            "Iteration 608/1000, Best Value: 0.16721594333648682, Temperature: 9.061799188292804e-06\n",
            "Iteration 609/1000, Best Value: 0.16721594333648682, Temperature: 8.78994521264402e-06\n",
            "Iteration 610/1000, Best Value: 0.16721594333648682, Temperature: 8.526246856264699e-06\n",
            "Iteration 611/1000, Best Value: 0.16721594333648682, Temperature: 8.270459450576758e-06\n",
            "Iteration 612/1000, Best Value: 0.16721594333648682, Temperature: 8.022345667059455e-06\n",
            "Iteration 613/1000, Best Value: 0.16721594333648682, Temperature: 7.781675297047672e-06\n",
            "Iteration 614/1000, Best Value: 0.16721594333648682, Temperature: 7.548225038136241e-06\n",
            "Iteration 615/1000, Best Value: 0.16721594333648682, Temperature: 7.3217782869921536e-06\n",
            "Iteration 616/1000, Best Value: 0.16721594333648682, Temperature: 7.1021249383823886e-06\n",
            "Iteration 617/1000, Best Value: 0.16721594333648682, Temperature: 6.889061190230917e-06\n",
            "Iteration 618/1000, Best Value: 0.16721594333648682, Temperature: 6.68238935452399e-06\n",
            "Iteration 619/1000, Best Value: 0.16721594333648682, Temperature: 6.48191767388827e-06\n",
            "Iteration 620/1000, Best Value: 0.16721594333648682, Temperature: 6.287460143671621e-06\n",
            "Iteration 621/1000, Best Value: 0.16721594333648682, Temperature: 6.098836339361473e-06\n",
            "Iteration 622/1000, Best Value: 0.16721594333648682, Temperature: 5.915871249180629e-06\n",
            "Iteration 623/1000, Best Value: 0.16721594333648682, Temperature: 5.73839511170521e-06\n",
            "Iteration 624/1000, Best Value: 0.16721594333648682, Temperature: 5.566243258354053e-06\n",
            "Iteration 625/1000, Best Value: 0.16721594333648682, Temperature: 5.399255960603432e-06\n",
            "Iteration 626/1000, Best Value: 0.16721594333648682, Temperature: 5.237278281785328e-06\n",
            "Iteration 627/1000, Best Value: 0.16721594333648682, Temperature: 5.080159933331769e-06\n",
            "Iteration 628/1000, Best Value: 0.16721594333648682, Temperature: 4.927755135331816e-06\n",
            "Iteration 629/1000, Best Value: 0.16721594333648682, Temperature: 4.7799224812718615e-06\n",
            "Iteration 630/1000, Best Value: 0.16721594333648682, Temperature: 4.636524806833706e-06\n",
            "Iteration 631/1000, Best Value: 0.16721594333648682, Temperature: 4.497429062628694e-06\n",
            "Iteration 632/1000, Best Value: 0.16721594333648682, Temperature: 4.362506190749833e-06\n",
            "Iteration 633/1000, Best Value: 0.16721594333648682, Temperature: 4.231631005027338e-06\n",
            "Iteration 634/1000, Best Value: 0.16721594333648682, Temperature: 4.104682074876518e-06\n",
            "Iteration 635/1000, Best Value: 0.16721594333648682, Temperature: 3.981541612630223e-06\n",
            "Iteration 636/1000, Best Value: 0.16721594333648682, Temperature: 3.862095364251316e-06\n",
            "Iteration 637/1000, Best Value: 0.16721594333648682, Temperature: 3.7462325033237763e-06\n",
            "Iteration 638/1000, Best Value: 0.16721594333648682, Temperature: 3.633845528224063e-06\n",
            "Iteration 639/1000, Best Value: 0.16721594333648682, Temperature: 3.524830162377341e-06\n",
            "Iteration 640/1000, Best Value: 0.16721594333648682, Temperature: 3.4190852575060207e-06\n",
            "Iteration 641/1000, Best Value: 0.16721594333648682, Temperature: 3.31651269978084e-06\n",
            "Iteration 642/1000, Best Value: 0.16721594333648682, Temperature: 3.2170173187874143e-06\n",
            "Iteration 643/1000, Best Value: 0.16721594333648682, Temperature: 3.120506799223792e-06\n",
            "Iteration 644/1000, Best Value: 0.16721594333648682, Temperature: 3.026891595247078e-06\n",
            "Iteration 645/1000, Best Value: 0.16721594333648682, Temperature: 2.9360848473896656e-06\n",
            "Iteration 646/1000, Best Value: 0.16721594333648682, Temperature: 2.8480023019679756e-06\n",
            "Iteration 647/1000, Best Value: 0.16721594333648682, Temperature: 2.762562232908936e-06\n",
            "Iteration 648/1000, Best Value: 0.16721594333648682, Temperature: 2.679685365921668e-06\n",
            "Iteration 649/1000, Best Value: 0.16721594333648682, Temperature: 2.599294804944018e-06\n",
            "Iteration 650/1000, Best Value: 0.16721594333648682, Temperature: 2.5213159607956974e-06\n",
            "Iteration 651/1000, Best Value: 0.16721594333648682, Temperature: 2.4456764819718266e-06\n",
            "Iteration 652/1000, Best Value: 0.16721594333648682, Temperature: 2.3723061875126716e-06\n",
            "Iteration 653/1000, Best Value: 0.16721594333648682, Temperature: 2.3011370018872913e-06\n",
            "Iteration 654/1000, Best Value: 0.16721594333648682, Temperature: 2.2321028918306727e-06\n",
            "Iteration 655/1000, Best Value: 0.16721594333648682, Temperature: 2.1651398050757524e-06\n",
            "Iteration 656/1000, Best Value: 0.16721594333648682, Temperature: 2.1001856109234797e-06\n",
            "Iteration 657/1000, Best Value: 0.16721594333648682, Temperature: 2.0371800425957754e-06\n",
            "Iteration 658/1000, Best Value: 0.16721594333648682, Temperature: 1.976064641317902e-06\n",
            "Iteration 659/1000, Best Value: 0.16721594333648682, Temperature: 1.916782702078365e-06\n",
            "Iteration 660/1000, Best Value: 0.16721594333648682, Temperature: 1.859279221016014e-06\n",
            "Iteration 661/1000, Best Value: 0.16721594333648682, Temperature: 1.8035008443855337e-06\n",
            "Iteration 662/1000, Best Value: 0.16721594333648682, Temperature: 1.7493958190539675e-06\n",
            "Iteration 663/1000, Best Value: 0.16721594333648682, Temperature: 1.6969139444823484e-06\n",
            "Iteration 664/1000, Best Value: 0.16721594333648682, Temperature: 1.646006526147878e-06\n",
            "Iteration 665/1000, Best Value: 0.16721594333648682, Temperature: 1.5966263303634416e-06\n",
            "Iteration 666/1000, Best Value: 0.16721594333648682, Temperature: 1.5487275404525384e-06\n",
            "Iteration 667/1000, Best Value: 0.16721594333648682, Temperature: 1.5022657142389623e-06\n",
            "Iteration 668/1000, Best Value: 0.16721594333648682, Temperature: 1.4571977428117935e-06\n",
            "Iteration 669/1000, Best Value: 0.16721594333648682, Temperature: 1.4134818105274396e-06\n",
            "Iteration 670/1000, Best Value: 0.16721594333648682, Temperature: 1.3710773562116163e-06\n",
            "Iteration 671/1000, Best Value: 0.16721594333648682, Temperature: 1.3299450355252677e-06\n",
            "Iteration 672/1000, Best Value: 0.16721594333648682, Temperature: 1.2900466844595097e-06\n",
            "Iteration 673/1000, Best Value: 0.16721594333648682, Temperature: 1.2513452839257245e-06\n",
            "Iteration 674/1000, Best Value: 0.16721594333648682, Temperature: 1.2138049254079528e-06\n",
            "Iteration 675/1000, Best Value: 0.16721594333648682, Temperature: 1.1773907776457142e-06\n",
            "Iteration 676/1000, Best Value: 0.16721594333648682, Temperature: 1.1420690543163427e-06\n",
            "Iteration 677/1000, Best Value: 0.16721594333648682, Temperature: 1.1078069826868524e-06\n",
            "Iteration 678/1000, Best Value: 0.16721594333648682, Temperature: 1.0745727732062469e-06\n",
            "Iteration 679/1000, Best Value: 0.16721594333648682, Temperature: 1.0423355900100595e-06\n",
            "Iteration 680/1000, Best Value: 0.16721594333648682, Temperature: 1.0110655223097576e-06\n",
            "Iteration 681/1000, Best Value: 0.16721594333648682, Temperature: 9.807335566404649e-07\n",
            "Iteration 682/1000, Best Value: 0.16721594333648682, Temperature: 9.513115499412509e-07\n",
            "Iteration 683/1000, Best Value: 0.16721594333648682, Temperature: 9.227722034430134e-07\n",
            "Iteration 684/1000, Best Value: 0.16721594333648682, Temperature: 8.95089037339723e-07\n",
            "Iteration 685/1000, Best Value: 0.16721594333648682, Temperature: 8.682363662195312e-07\n",
            "Iteration 686/1000, Best Value: 0.16721594333648682, Temperature: 8.421892752329453e-07\n",
            "Iteration 687/1000, Best Value: 0.16721594333648682, Temperature: 8.169235969759569e-07\n",
            "Iteration 688/1000, Best Value: 0.16721594333648682, Temperature: 7.924158890666782e-07\n",
            "Iteration 689/1000, Best Value: 0.16721594333648682, Temperature: 7.686434123946778e-07\n",
            "Iteration 690/1000, Best Value: 0.16721594333648682, Temperature: 7.455841100228375e-07\n",
            "Iteration 691/1000, Best Value: 0.16721594333648682, Temperature: 7.232165867221523e-07\n",
            "Iteration 692/1000, Best Value: 0.16721594333648682, Temperature: 7.015200891204877e-07\n",
            "Iteration 693/1000, Best Value: 0.16721594333648682, Temperature: 6.804744864468731e-07\n",
            "Iteration 694/1000, Best Value: 0.16721594333648682, Temperature: 6.600602518534669e-07\n",
            "Iteration 695/1000, Best Value: 0.16721594333648682, Temperature: 6.402584442978628e-07\n",
            "Iteration 696/1000, Best Value: 0.16721594333648682, Temperature: 6.210506909689268e-07\n",
            "Iteration 697/1000, Best Value: 0.16721594333648682, Temperature: 6.02419170239859e-07\n",
            "Iteration 698/1000, Best Value: 0.16721594333648682, Temperature: 5.843465951326633e-07\n",
            "Iteration 699/1000, Best Value: 0.16721594333648682, Temperature: 5.668161972786834e-07\n",
            "Iteration 700/1000, Best Value: 0.16721594333648682, Temperature: 5.498117113603229e-07\n",
            "Iteration 701/1000, Best Value: 0.16721594333648682, Temperature: 5.333173600195132e-07\n",
            "Iteration 702/1000, Best Value: 0.16721594333648682, Temperature: 5.173178392189278e-07\n",
            "Iteration 703/1000, Best Value: 0.16721594333648682, Temperature: 5.017983040423599e-07\n",
            "Iteration 704/1000, Best Value: 0.16721594333648682, Temperature: 4.867443549210891e-07\n",
            "Iteration 705/1000, Best Value: 0.16721594333648682, Temperature: 4.7214202427345646e-07\n",
            "Iteration 706/1000, Best Value: 0.16721594333648682, Temperature: 4.5797776354525275e-07\n",
            "Iteration 707/1000, Best Value: 0.16721594333648682, Temperature: 4.442384306388952e-07\n",
            "Iteration 708/1000, Best Value: 0.16721594333648682, Temperature: 4.309112777197283e-07\n",
            "Iteration 709/1000, Best Value: 0.16721594333648682, Temperature: 4.179839393881364e-07\n",
            "Iteration 710/1000, Best Value: 0.16721594333648682, Temperature: 4.054444212064923e-07\n",
            "Iteration 711/1000, Best Value: 0.16721594333648682, Temperature: 3.932810885702975e-07\n",
            "Iteration 712/1000, Best Value: 0.16721594333648682, Temperature: 3.8148265591318854e-07\n",
            "Iteration 713/1000, Best Value: 0.16721594333648682, Temperature: 3.700381762357929e-07\n",
            "Iteration 714/1000, Best Value: 0.16721594333648682, Temperature: 3.5893703094871913e-07\n",
            "Iteration 715/1000, Best Value: 0.16721594333648682, Temperature: 3.4816892002025756e-07\n",
            "Iteration 716/1000, Best Value: 0.16721594333648682, Temperature: 3.377238524196498e-07\n",
            "Iteration 717/1000, Best Value: 0.16721594333648682, Temperature: 3.275921368470603e-07\n",
            "Iteration 718/1000, Best Value: 0.16721594333648682, Temperature: 3.177643727416485e-07\n",
            "Iteration 719/1000, Best Value: 0.16721594333648682, Temperature: 3.08231441559399e-07\n",
            "Iteration 720/1000, Best Value: 0.16721594333648682, Temperature: 2.9898449831261705e-07\n",
            "Iteration 721/1000, Best Value: 0.16721594333648682, Temperature: 2.9001496336323853e-07\n",
            "Iteration 722/1000, Best Value: 0.16721594333648682, Temperature: 2.813145144623414e-07\n",
            "Iteration 723/1000, Best Value: 0.16721594333648682, Temperature: 2.7287507902847114e-07\n",
            "Iteration 724/1000, Best Value: 0.16721594333648682, Temperature: 2.64688826657617e-07\n",
            "Iteration 725/1000, Best Value: 0.16721594333648682, Temperature: 2.567481618578885e-07\n",
            "Iteration 726/1000, Best Value: 0.16721594333648682, Temperature: 2.4904571700215183e-07\n",
            "Iteration 727/1000, Best Value: 0.16721594333648682, Temperature: 2.415743454920873e-07\n",
            "Iteration 728/1000, Best Value: 0.16721594333648682, Temperature: 2.3432711512732467e-07\n",
            "Iteration 729/1000, Best Value: 0.16721594333648682, Temperature: 2.2729730167350491e-07\n",
            "Iteration 730/1000, Best Value: 0.16721594333648682, Temperature: 2.2047838262329976e-07\n",
            "Iteration 731/1000, Best Value: 0.16721594333648682, Temperature: 2.1386403114460077e-07\n",
            "Iteration 732/1000, Best Value: 0.16721594333648682, Temperature: 2.0744811021026274e-07\n",
            "Iteration 733/1000, Best Value: 0.16721594333648682, Temperature: 2.0122466690395484e-07\n",
            "Iteration 734/1000, Best Value: 0.16721594333648682, Temperature: 1.951879268968362e-07\n",
            "Iteration 735/1000, Best Value: 0.16721594333648682, Temperature: 1.893322890899311e-07\n",
            "Iteration 736/1000, Best Value: 0.16721594333648682, Temperature: 1.8365232041723316e-07\n",
            "Iteration 737/1000, Best Value: 0.16721594333648682, Temperature: 1.7814275080471616e-07\n",
            "Iteration 738/1000, Best Value: 0.16721594333648682, Temperature: 1.7279846828057467e-07\n",
            "Iteration 739/1000, Best Value: 0.16721594333648682, Temperature: 1.6761451423215743e-07\n",
            "Iteration 740/1000, Best Value: 0.16721594333648682, Temperature: 1.625860788051927e-07\n",
            "Iteration 741/1000, Best Value: 0.16721594333648682, Temperature: 1.5770849644103692e-07\n",
            "Iteration 742/1000, Best Value: 0.16721594333648682, Temperature: 1.529772415478058e-07\n",
            "Iteration 743/1000, Best Value: 0.16721594333648682, Temperature: 1.4838792430137163e-07\n",
            "Iteration 744/1000, Best Value: 0.16721594333648682, Temperature: 1.4393628657233048e-07\n",
            "Iteration 745/1000, Best Value: 0.16721594333648682, Temperature: 1.3961819797516055e-07\n",
            "Iteration 746/1000, Best Value: 0.16721594333648682, Temperature: 1.3542965203590572e-07\n",
            "Iteration 747/1000, Best Value: 0.16721594333648682, Temperature: 1.3136676247482854e-07\n",
            "Iteration 748/1000, Best Value: 0.16721594333648682, Temperature: 1.2742575960058367e-07\n",
            "Iteration 749/1000, Best Value: 0.16721594333648682, Temperature: 1.2360298681256617e-07\n",
            "Iteration 750/1000, Best Value: 0.16721594333648682, Temperature: 1.1989489720818918e-07\n",
            "Iteration 751/1000, Best Value: 0.16721594333648682, Temperature: 1.1629805029194351e-07\n",
            "Iteration 752/1000, Best Value: 0.16721594333648682, Temperature: 1.128091087831852e-07\n",
            "Iteration 753/1000, Best Value: 0.16721594333648682, Temperature: 1.0942483551968964e-07\n",
            "Iteration 754/1000, Best Value: 0.16721594333648682, Temperature: 1.0614209045409895e-07\n",
            "Iteration 755/1000, Best Value: 0.16721594333648682, Temperature: 1.0295782774047597e-07\n",
            "Iteration 756/1000, Best Value: 0.16721594333648682, Temperature: 9.986909290826169e-08\n",
            "Iteration 757/1000, Best Value: 0.16721594333648682, Temperature: 9.687302012101383e-08\n",
            "Iteration 758/1000, Best Value: 0.16721594333648682, Temperature: 9.39668295173834e-08\n",
            "Iteration 759/1000, Best Value: 0.16721594333648682, Temperature: 9.11478246318619e-08\n",
            "Iteration 760/1000, Best Value: 0.16721594333648682, Temperature: 8.841338989290604e-08\n",
            "Iteration 761/1000, Best Value: 0.16721594333648682, Temperature: 8.576098819611885e-08\n",
            "Iteration 762/1000, Best Value: 0.16721594333648682, Temperature: 8.318815855023528e-08\n",
            "Iteration 763/1000, Best Value: 0.16721594333648682, Temperature: 8.069251379372822e-08\n",
            "Iteration 764/1000, Best Value: 0.16721594333648682, Temperature: 7.827173837991637e-08\n",
            "Iteration 765/1000, Best Value: 0.16721594333648682, Temperature: 7.592358622851888e-08\n",
            "Iteration 766/1000, Best Value: 0.16721594333648682, Temperature: 7.364587864166331e-08\n",
            "Iteration 767/1000, Best Value: 0.16721594333648682, Temperature: 7.143650228241341e-08\n",
            "Iteration 768/1000, Best Value: 0.16721594333648682, Temperature: 6.9293407213941e-08\n",
            "Iteration 769/1000, Best Value: 0.16721594333648682, Temperature: 6.721460499752278e-08\n",
            "Iteration 770/1000, Best Value: 0.16721594333648682, Temperature: 6.519816684759709e-08\n",
            "Iteration 771/1000, Best Value: 0.16721594333648682, Temperature: 6.324222184216918e-08\n",
            "Iteration 772/1000, Best Value: 0.16721594333648682, Temperature: 6.13449551869041e-08\n",
            "Iteration 773/1000, Best Value: 0.16721594333648682, Temperature: 5.950460653129697e-08\n",
            "Iteration 774/1000, Best Value: 0.16721594333648682, Temperature: 5.771946833535806e-08\n",
            "Iteration 775/1000, Best Value: 0.16721594333648682, Temperature: 5.5987884285297314e-08\n",
            "Iteration 776/1000, Best Value: 0.16721594333648682, Temperature: 5.4308247756738396e-08\n",
            "Iteration 777/1000, Best Value: 0.16721594333648682, Temperature: 5.2679000324036244e-08\n",
            "Iteration 778/1000, Best Value: 0.16721594333648682, Temperature: 5.1098630314315154e-08\n",
            "Iteration 779/1000, Best Value: 0.16721594333648682, Temperature: 4.95656714048857e-08\n",
            "Iteration 780/1000, Best Value: 0.16721594333648682, Temperature: 4.807870126273913e-08\n",
            "Iteration 781/1000, Best Value: 0.16721594333648682, Temperature: 4.663634022485696e-08\n",
            "Iteration 782/1000, Best Value: 0.16721594333648682, Temperature: 4.523725001811125e-08\n",
            "Iteration 783/1000, Best Value: 0.16721594333648682, Temperature: 4.388013251756791e-08\n",
            "Iteration 784/1000, Best Value: 0.16721594333648682, Temperature: 4.256372854204087e-08\n",
            "Iteration 785/1000, Best Value: 0.16721594333648682, Temperature: 4.1286816685779644e-08\n",
            "Iteration 786/1000, Best Value: 0.16721594333648682, Temperature: 4.004821218520625e-08\n",
            "Iteration 787/1000, Best Value: 0.16721594333648682, Temperature: 3.8846765819650064e-08\n",
            "Iteration 788/1000, Best Value: 0.16721594333648682, Temperature: 3.768136284506056e-08\n",
            "Iteration 789/1000, Best Value: 0.16721594333648682, Temperature: 3.655092195970874e-08\n",
            "Iteration 790/1000, Best Value: 0.16721594333648682, Temperature: 3.545439430091748e-08\n",
            "Iteration 791/1000, Best Value: 0.16721594333648682, Temperature: 3.439076247188995e-08\n",
            "Iteration 792/1000, Best Value: 0.16721594333648682, Temperature: 3.3359039597733254e-08\n",
            "Iteration 793/1000, Best Value: 0.16721594333648682, Temperature: 3.2358268409801254e-08\n",
            "Iteration 794/1000, Best Value: 0.16721594333648682, Temperature: 3.138752035750722e-08\n",
            "Iteration 795/1000, Best Value: 0.16721594333648682, Temperature: 3.0445894746782e-08\n",
            "Iteration 796/1000, Best Value: 0.16721594333648682, Temperature: 2.953251790437854e-08\n",
            "Iteration 797/1000, Best Value: 0.16721594333648682, Temperature: 2.8646542367247183e-08\n",
            "Iteration 798/1000, Best Value: 0.16721594333648682, Temperature: 2.7787146096229768e-08\n",
            "Iteration 799/1000, Best Value: 0.16721594333648682, Temperature: 2.6953531713342876e-08\n",
            "Iteration 800/1000, Best Value: 0.16721594333648682, Temperature: 2.6144925761942588e-08\n",
            "Iteration 801/1000, Best Value: 0.16721594333648682, Temperature: 2.536057798908431e-08\n",
            "Iteration 802/1000, Best Value: 0.16721594333648682, Temperature: 2.4599760649411778e-08\n",
            "Iteration 803/1000, Best Value: 0.16721594333648682, Temperature: 2.3861767829929424e-08\n",
            "Iteration 804/1000, Best Value: 0.16721594333648682, Temperature: 2.314591479503154e-08\n",
            "Iteration 805/1000, Best Value: 0.16721594333648682, Temperature: 2.2451537351180594e-08\n",
            "Iteration 806/1000, Best Value: 0.16721594333648682, Temperature: 2.1777991230645174e-08\n",
            "Iteration 807/1000, Best Value: 0.16721594333648682, Temperature: 2.1124651493725817e-08\n",
            "Iteration 808/1000, Best Value: 0.16721594333648682, Temperature: 2.0490911948914043e-08\n",
            "Iteration 809/1000, Best Value: 0.16721594333648682, Temperature: 1.987618459044662e-08\n",
            "Iteration 810/1000, Best Value: 0.16721594333648682, Temperature: 1.9279899052733223e-08\n",
            "Iteration 811/1000, Best Value: 0.16721594333648682, Temperature: 1.8701502081151227e-08\n",
            "Iteration 812/1000, Best Value: 0.16721594333648682, Temperature: 1.814045701871669e-08\n",
            "Iteration 813/1000, Best Value: 0.16639146208763123, Temperature: 1.759624330815519e-08\n",
            "Iteration 814/1000, Best Value: 0.16639146208763123, Temperature: 1.7068356008910534e-08\n",
            "Iteration 815/1000, Best Value: 0.16639146208763123, Temperature: 1.655630532864322e-08\n",
            "Iteration 816/1000, Best Value: 0.16639146208763123, Temperature: 1.605961616878392e-08\n",
            "Iteration 817/1000, Best Value: 0.16639146208763123, Temperature: 1.5577827683720403e-08\n",
            "Iteration 818/1000, Best Value: 0.16639146208763123, Temperature: 1.511049285320879e-08\n",
            "Iteration 819/1000, Best Value: 0.16639146208763123, Temperature: 1.4657178067612525e-08\n",
            "Iteration 820/1000, Best Value: 0.16639146208763123, Temperature: 1.4217462725584148e-08\n",
            "Iteration 821/1000, Best Value: 0.16639146208763123, Temperature: 1.3790938843816623e-08\n",
            "Iteration 822/1000, Best Value: 0.16639146208763123, Temperature: 1.3377210678502124e-08\n",
            "Iteration 823/1000, Best Value: 0.16639146208763123, Temperature: 1.297589435814706e-08\n",
            "Iteration 824/1000, Best Value: 0.16639146208763123, Temperature: 1.2586617527402648e-08\n",
            "Iteration 825/1000, Best Value: 0.16639146208763123, Temperature: 1.2209019001580568e-08\n",
            "Iteration 826/1000, Best Value: 0.16639146208763123, Temperature: 1.184274843153315e-08\n",
            "Iteration 827/1000, Best Value: 0.16639146208763123, Temperature: 1.1487465978587156e-08\n",
            "Iteration 828/1000, Best Value: 0.16639146208763123, Temperature: 1.1142841999229541e-08\n",
            "Iteration 829/1000, Best Value: 0.16639146208763123, Temperature: 1.0808556739252655e-08\n",
            "Iteration 830/1000, Best Value: 0.16639146208763123, Temperature: 1.0484300037075075e-08\n",
            "Iteration 831/1000, Best Value: 0.16639146208763123, Temperature: 1.0169771035962823e-08\n",
            "Iteration 832/1000, Best Value: 0.16639146208763123, Temperature: 9.864677904883938e-09\n",
            "Iteration 833/1000, Best Value: 0.16639146208763123, Temperature: 9.56873756773742e-09\n",
            "Iteration 834/1000, Best Value: 0.16639146208763123, Temperature: 9.281675440705297e-09\n",
            "Iteration 835/1000, Best Value: 0.16639146208763123, Temperature: 9.003225177484137e-09\n",
            "Iteration 836/1000, Best Value: 0.16639146208763123, Temperature: 8.733128422159613e-09\n",
            "Iteration 837/1000, Best Value: 0.16639146208763123, Temperature: 8.471134569494825e-09\n",
            "Iteration 838/1000, Best Value: 0.16639146208763123, Temperature: 8.21700053240998e-09\n",
            "Iteration 839/1000, Best Value: 0.16639146208763123, Temperature: 7.97049051643768e-09\n",
            "Iteration 840/1000, Best Value: 0.16639146208763123, Temperature: 7.73137580094455e-09\n",
            "Iteration 841/1000, Best Value: 0.16639146208763123, Temperature: 7.499434526916213e-09\n",
            "Iteration 842/1000, Best Value: 0.16639146208763123, Temperature: 7.274451491108727e-09\n",
            "Iteration 843/1000, Best Value: 0.16639146208763123, Temperature: 7.0562179463754646e-09\n",
            "Iteration 844/1000, Best Value: 0.16639146208763123, Temperature: 6.8445314079842e-09\n",
            "Iteration 845/1000, Best Value: 0.16639146208763123, Temperature: 6.639195465744674e-09\n",
            "Iteration 846/1000, Best Value: 0.16639146208763123, Temperature: 6.4400196017723334e-09\n",
            "Iteration 847/1000, Best Value: 0.16639146208763123, Temperature: 6.246819013719163e-09\n",
            "Iteration 848/1000, Best Value: 0.16639146208763123, Temperature: 6.059414443307588e-09\n",
            "Iteration 849/1000, Best Value: 0.16639146208763123, Temperature: 5.87763201000836e-09\n",
            "Iteration 850/1000, Best Value: 0.16639146208763123, Temperature: 5.701303049708109e-09\n",
            "Iteration 851/1000, Best Value: 0.16639146208763123, Temperature: 5.530263958216866e-09\n",
            "Iteration 852/1000, Best Value: 0.16639146208763123, Temperature: 5.36435603947036e-09\n",
            "Iteration 853/1000, Best Value: 0.16639146208763123, Temperature: 5.203425358286249e-09\n",
            "Iteration 854/1000, Best Value: 0.16639146208763123, Temperature: 5.047322597537661e-09\n",
            "Iteration 855/1000, Best Value: 0.16639146208763123, Temperature: 4.895902919611531e-09\n",
            "Iteration 856/1000, Best Value: 0.16639146208763123, Temperature: 4.749025832023185e-09\n",
            "Iteration 857/1000, Best Value: 0.16639146208763123, Temperature: 4.6065550570624895e-09\n",
            "Iteration 858/1000, Best Value: 0.16639146208763123, Temperature: 4.4683584053506145e-09\n",
            "Iteration 859/1000, Best Value: 0.16639146208763123, Temperature: 4.334307653190096e-09\n",
            "Iteration 860/1000, Best Value: 0.16639146208763123, Temperature: 4.204278423594393e-09\n",
            "Iteration 861/1000, Best Value: 0.16639146208763123, Temperature: 4.078150070886561e-09\n",
            "Iteration 862/1000, Best Value: 0.16639146208763123, Temperature: 3.955805568759964e-09\n",
            "Iteration 863/1000, Best Value: 0.16639146208763123, Temperature: 3.837131401697165e-09\n",
            "Iteration 864/1000, Best Value: 0.16639146208763123, Temperature: 3.7220174596462498e-09\n",
            "Iteration 865/1000, Best Value: 0.16639146208763123, Temperature: 3.6103569358568624e-09\n",
            "Iteration 866/1000, Best Value: 0.16639146208763123, Temperature: 3.5020462277811565e-09\n",
            "Iteration 867/1000, Best Value: 0.16639146208763123, Temperature: 3.3969848409477215e-09\n",
            "Iteration 868/1000, Best Value: 0.16639146208763123, Temperature: 3.2950752957192898e-09\n",
            "Iteration 869/1000, Best Value: 0.16639146208763123, Temperature: 3.196223036847711e-09\n",
            "Iteration 870/1000, Best Value: 0.16639146208763123, Temperature: 3.1003363457422794e-09\n",
            "Iteration 871/1000, Best Value: 0.16639146208763123, Temperature: 3.007326255370011e-09\n",
            "Iteration 872/1000, Best Value: 0.16639146208763123, Temperature: 2.9171064677089106e-09\n",
            "Iteration 873/1000, Best Value: 0.16639146208763123, Temperature: 2.829593273677643e-09\n",
            "Iteration 874/1000, Best Value: 0.16639146208763123, Temperature: 2.744705475467314e-09\n",
            "Iteration 875/1000, Best Value: 0.16639146208763123, Temperature: 2.6623643112032945e-09\n",
            "Iteration 876/1000, Best Value: 0.16639146208763123, Temperature: 2.5824933818671956e-09\n",
            "Iteration 877/1000, Best Value: 0.16639146208763123, Temperature: 2.50501858041118e-09\n",
            "Iteration 878/1000, Best Value: 0.16639146208763123, Temperature: 2.4298680229988443e-09\n",
            "Iteration 879/1000, Best Value: 0.16639146208763123, Temperature: 2.3569719823088788e-09\n",
            "Iteration 880/1000, Best Value: 0.16639146208763123, Temperature: 2.2862628228396123e-09\n",
            "Iteration 881/1000, Best Value: 0.16639146208763123, Temperature: 2.217674938154424e-09\n",
            "Iteration 882/1000, Best Value: 0.16639146208763123, Temperature: 2.151144690009791e-09\n",
            "Iteration 883/1000, Best Value: 0.16639146208763123, Temperature: 2.086610349309497e-09\n",
            "Iteration 884/1000, Best Value: 0.16639146208763123, Temperature: 2.0240120388302123e-09\n",
            "Iteration 885/1000, Best Value: 0.16639146208763123, Temperature: 1.9632916776653057e-09\n",
            "Iteration 886/1000, Best Value: 0.16639146208763123, Temperature: 1.9043929273353463e-09\n",
            "Iteration 887/1000, Best Value: 0.16639146208763123, Temperature: 1.8472611395152858e-09\n",
            "Iteration 888/1000, Best Value: 0.16639146208763123, Temperature: 1.7918433053298271e-09\n",
            "Iteration 889/1000, Best Value: 0.16639146208763123, Temperature: 1.7380880061699323e-09\n",
            "Iteration 890/1000, Best Value: 0.16639146208763123, Temperature: 1.6859453659848343e-09\n",
            "Iteration 891/1000, Best Value: 0.16639146208763123, Temperature: 1.6353670050052893e-09\n",
            "Iteration 892/1000, Best Value: 0.16639146208763123, Temperature: 1.5863059948551306e-09\n",
            "Iteration 893/1000, Best Value: 0.16639146208763123, Temperature: 1.5387168150094766e-09\n",
            "Iteration 894/1000, Best Value: 0.16639146208763123, Temperature: 1.4925553105591924e-09\n",
            "Iteration 895/1000, Best Value: 0.16639146208763123, Temperature: 1.4477786512424165e-09\n",
            "Iteration 896/1000, Best Value: 0.16639146208763123, Temperature: 1.404345291705144e-09\n",
            "Iteration 897/1000, Best Value: 0.16639146208763123, Temperature: 1.3622149329539896e-09\n",
            "Iteration 898/1000, Best Value: 0.16639146208763123, Temperature: 1.3213484849653698e-09\n",
            "Iteration 899/1000, Best Value: 0.16639146208763123, Temperature: 1.2817080304164087e-09\n",
            "Iteration 900/1000, Best Value: 0.16639146208763123, Temperature: 1.2432567895039165e-09\n",
            "Iteration 901/1000, Best Value: 0.16639146208763123, Temperature: 1.205959085818799e-09\n",
            "Iteration 902/1000, Best Value: 0.16639146208763123, Temperature: 1.169780313244235e-09\n",
            "Iteration 903/1000, Best Value: 0.16639146208763123, Temperature: 1.134686903846908e-09\n",
            "Iteration 904/1000, Best Value: 0.16639146208763123, Temperature: 1.1006462967315008e-09\n",
            "Iteration 905/1000, Best Value: 0.16639146208763123, Temperature: 1.0676269078295559e-09\n",
            "Iteration 906/1000, Best Value: 0.16639146208763123, Temperature: 1.0355981005946693e-09\n",
            "Iteration 907/1000, Best Value: 0.16639146208763123, Temperature: 1.0045301575768291e-09\n",
            "Iteration 908/1000, Best Value: 0.16639146208763123, Temperature: 9.743942528495242e-10\n",
            "Iteration 909/1000, Best Value: 0.16639146208763123, Temperature: 9.451624252640383e-10\n",
            "Iteration 910/1000, Best Value: 0.16639146208763123, Temperature: 9.168075525061172e-10\n",
            "Iteration 911/1000, Best Value: 0.16639146208763123, Temperature: 8.893033259309336e-10\n",
            "Iteration 912/1000, Best Value: 0.16639146208763123, Temperature: 8.626242261530056e-10\n",
            "Iteration 913/1000, Best Value: 0.16639146208763123, Temperature: 8.367454993684154e-10\n",
            "Iteration 914/1000, Best Value: 0.16639146208763123, Temperature: 8.116431343873629e-10\n",
            "Iteration 915/1000, Best Value: 0.16639146208763123, Temperature: 7.87293840355742e-10\n",
            "Iteration 916/1000, Best Value: 0.16639146208763123, Temperature: 7.636750251450697e-10\n",
            "Iteration 917/1000, Best Value: 0.16639146208763123, Temperature: 7.407647743907176e-10\n",
            "Iteration 918/1000, Best Value: 0.16639146208763123, Temperature: 7.18541831158996e-10\n",
            "Iteration 919/1000, Best Value: 0.16639146208763123, Temperature: 6.969855762242261e-10\n",
            "Iteration 920/1000, Best Value: 0.16639146208763123, Temperature: 6.760760089374993e-10\n",
            "Iteration 921/1000, Best Value: 0.16639146208763123, Temperature: 6.557937286693744e-10\n",
            "Iteration 922/1000, Best Value: 0.16639146208763123, Temperature: 6.361199168092931e-10\n",
            "Iteration 923/1000, Best Value: 0.16639146208763123, Temperature: 6.170363193050142e-10\n",
            "Iteration 924/1000, Best Value: 0.16639146208763123, Temperature: 5.985252297258638e-10\n",
            "Iteration 925/1000, Best Value: 0.16639146208763123, Temperature: 5.805694728340879e-10\n",
            "Iteration 926/1000, Best Value: 0.16639146208763123, Temperature: 5.631523886490652e-10\n",
            "Iteration 927/1000, Best Value: 0.16639146208763123, Temperature: 5.462578169895932e-10\n",
            "Iteration 928/1000, Best Value: 0.16639146208763123, Temperature: 5.298700824799055e-10\n",
            "Iteration 929/1000, Best Value: 0.16639146208763123, Temperature: 5.139739800055083e-10\n",
            "Iteration 930/1000, Best Value: 0.16639146208763123, Temperature: 4.98554760605343e-10\n",
            "Iteration 931/1000, Best Value: 0.16639146208763123, Temperature: 4.835981177871826e-10\n",
            "Iteration 932/1000, Best Value: 0.16639146208763123, Temperature: 4.690901742535671e-10\n",
            "Iteration 933/1000, Best Value: 0.16639146208763123, Temperature: 4.5501746902596014e-10\n",
            "Iteration 934/1000, Best Value: 0.16639146208763123, Temperature: 4.413669449551813e-10\n",
            "Iteration 935/1000, Best Value: 0.16639146208763123, Temperature: 4.2812593660652587e-10\n",
            "Iteration 936/1000, Best Value: 0.16639146208763123, Temperature: 4.152821585083301e-10\n",
            "Iteration 937/1000, Best Value: 0.16639146208763123, Temperature: 4.0282369375308016e-10\n",
            "Iteration 938/1000, Best Value: 0.16639146208763123, Temperature: 3.9073898294048774e-10\n",
            "Iteration 939/1000, Best Value: 0.16639146208763123, Temperature: 3.790168134522731e-10\n",
            "Iteration 940/1000, Best Value: 0.16639146208763123, Temperature: 3.676463090487049e-10\n",
            "Iteration 941/1000, Best Value: 0.16639146208763123, Temperature: 3.566169197772437e-10\n",
            "Iteration 942/1000, Best Value: 0.16639146208763123, Temperature: 3.4591841218392637e-10\n",
            "Iteration 943/1000, Best Value: 0.16639146208763123, Temperature: 3.355408598184086e-10\n",
            "Iteration 944/1000, Best Value: 0.16639146208763123, Temperature: 3.2547463402385634e-10\n",
            "Iteration 945/1000, Best Value: 0.16639146208763123, Temperature: 3.1571039500314064e-10\n",
            "Iteration 946/1000, Best Value: 0.16639146208763123, Temperature: 3.062390831530464e-10\n",
            "Iteration 947/1000, Best Value: 0.16639146208763123, Temperature: 2.97051910658455e-10\n",
            "Iteration 948/1000, Best Value: 0.16639146208763123, Temperature: 2.8814035333870134e-10\n",
            "Iteration 949/1000, Best Value: 0.16639146208763123, Temperature: 2.794961427385403e-10\n",
            "Iteration 950/1000, Best Value: 0.16639146208763123, Temperature: 2.711112584563841e-10\n",
            "Iteration 951/1000, Best Value: 0.16639146208763123, Temperature: 2.6297792070269256e-10\n",
            "Iteration 952/1000, Best Value: 0.16639146208763123, Temperature: 2.5508858308161177e-10\n",
            "Iteration 953/1000, Best Value: 0.16639146208763123, Temperature: 2.474359255891634e-10\n",
            "Iteration 954/1000, Best Value: 0.16639146208763123, Temperature: 2.400128478214885e-10\n",
            "Iteration 955/1000, Best Value: 0.16639146208763123, Temperature: 2.3281246238684384e-10\n",
            "Iteration 956/1000, Best Value: 0.16639146208763123, Temperature: 2.2582808851523852e-10\n",
            "Iteration 957/1000, Best Value: 0.16639146208763123, Temperature: 2.1905324585978137e-10\n",
            "Iteration 958/1000, Best Value: 0.16639146208763123, Temperature: 2.1248164848398792e-10\n",
            "Iteration 959/1000, Best Value: 0.16639146208763123, Temperature: 2.0610719902946828e-10\n",
            "Iteration 960/1000, Best Value: 0.16639146208763123, Temperature: 1.999239830585842e-10\n",
            "Iteration 961/1000, Best Value: 0.16639146208763123, Temperature: 1.9392626356682667e-10\n",
            "Iteration 962/1000, Best Value: 0.16639146208763123, Temperature: 1.8810847565982185e-10\n",
            "Iteration 963/1000, Best Value: 0.16639146208763123, Temperature: 1.8246522139002718e-10\n",
            "Iteration 964/1000, Best Value: 0.16639146208763123, Temperature: 1.7699126474832637e-10\n",
            "Iteration 965/1000, Best Value: 0.16639146208763123, Temperature: 1.7168152680587659e-10\n",
            "Iteration 966/1000, Best Value: 0.16639146208763123, Temperature: 1.6653108100170029e-10\n",
            "Iteration 967/1000, Best Value: 0.16639146208763123, Temperature: 1.6153514857164928e-10\n",
            "Iteration 968/1000, Best Value: 0.16639146208763123, Temperature: 1.566890941144998e-10\n",
            "Iteration 969/1000, Best Value: 0.16639146208763123, Temperature: 1.519884212910648e-10\n",
            "Iteration 970/1000, Best Value: 0.16639146208763123, Temperature: 1.4742876865233284e-10\n",
            "Iteration 971/1000, Best Value: 0.16639146208763123, Temperature: 1.4300590559276286e-10\n",
            "Iteration 972/1000, Best Value: 0.16639146208763123, Temperature: 1.3871572842497997e-10\n",
            "Iteration 973/1000, Best Value: 0.16639146208763123, Temperature: 1.3455425657223056e-10\n",
            "Iteration 974/1000, Best Value: 0.16639146208763123, Temperature: 1.3051762887506365e-10\n",
            "Iteration 975/1000, Best Value: 0.16639146208763123, Temperature: 1.2660210000881173e-10\n",
            "Iteration 976/1000, Best Value: 0.16639146208763123, Temperature: 1.2280403700854736e-10\n",
            "Iteration 977/1000, Best Value: 0.16639146208763123, Temperature: 1.1911991589829093e-10\n",
            "Iteration 978/1000, Best Value: 0.16639146208763123, Temperature: 1.155463184213422e-10\n",
            "Iteration 979/1000, Best Value: 0.16639146208763123, Temperature: 1.1207992886870194e-10\n",
            "Iteration 980/1000, Best Value: 0.16639146208763123, Temperature: 1.0871753100264088e-10\n",
            "Iteration 981/1000, Best Value: 0.16639146208763123, Temperature: 1.0545600507256166e-10\n",
            "Iteration 982/1000, Best Value: 0.16639146208763123, Temperature: 1.022923249203848e-10\n",
            "Iteration 983/1000, Best Value: 0.16639146208763123, Temperature: 9.922355517277325e-11\n",
            "Iteration 984/1000, Best Value: 0.16639146208763123, Temperature: 9.624684851759005e-11\n",
            "Iteration 985/1000, Best Value: 0.16639146208763123, Temperature: 9.335944306206235e-11\n",
            "Iteration 986/1000, Best Value: 0.16639146208763123, Temperature: 9.055865977020047e-11\n",
            "Iteration 987/1000, Best Value: 0.16639146208763123, Temperature: 8.784189997709445e-11\n",
            "Iteration 988/1000, Best Value: 0.16639146208763123, Temperature: 8.520664297778162e-11\n",
            "Iteration 989/1000, Best Value: 0.16639146208763123, Temperature: 8.265044368844817e-11\n",
            "Iteration 990/1000, Best Value: 0.16639146208763123, Temperature: 8.017093037779472e-11\n",
            "Iteration 991/1000, Best Value: 0.16639146208763123, Temperature: 7.776580246646089e-11\n",
            "Iteration 992/1000, Best Value: 0.16639146208763123, Temperature: 7.543282839246706e-11\n",
            "Iteration 993/1000, Best Value: 0.16639146208763123, Temperature: 7.316984354069304e-11\n",
            "Iteration 994/1000, Best Value: 0.16639146208763123, Temperature: 7.097474823447224e-11\n",
            "Iteration 995/1000, Best Value: 0.16639146208763123, Temperature: 6.884550578743807e-11\n",
            "Iteration 996/1000, Best Value: 0.16639146208763123, Temperature: 6.678014061381492e-11\n",
            "Iteration 997/1000, Best Value: 0.16639146208763123, Temperature: 6.477673639540047e-11\n",
            "Iteration 998/1000, Best Value: 0.16639146208763123, Temperature: 6.283343430353846e-11\n",
            "Iteration 999/1000, Best Value: 0.16639146208763123, Temperature: 6.09484312744323e-11\n",
            "Iteration 1000/1000, Best Value: 0.16639146208763123, Temperature: 5.911997833619933e-11\n",
            "Best Solution: [33.24287058 10.06843892 11.85901311], Best Value: 0.16639146208763123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od_Q-ckZv0Yu",
        "outputId": "10de283a-c22e-4d6a-a920-21a1b1c46ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0: Best Fitness = 0.20802593231201172, Best Individual = [23.861684351362246, 8.767529966802856, 17.905015119296305]\n",
            "Generation 1: Best Fitness = 0.2614586651325226, Best Individual = [26.779534272956603, 19.494973017999158, 14.629245041942827]\n",
            "Generation 2: Best Fitness = 0.2017790675163269, Best Individual = [26.779534272956603, 7.72104748764787, 15.55559359890333]\n",
            "Generation 3: Best Fitness = 0.2195850908756256, Best Individual = [26.779534272956603, 7.72104748764787, 18.343729273523387]\n",
            "Generation 4: Best Fitness = 0.2450794279575348, Best Individual = [26.093207076644504, 16.99798146854881, 15.55559359890333]\n",
            "Generation 5: Best Fitness = 0.2195850908756256, Best Individual = [26.779534272956603, 7.72104748764787, 18.343729273523387]\n",
            "Generation 6: Best Fitness = 0.2066776156425476, Best Individual = [26.779534272956603, 9.545048698493122, 15.55559359890333]\n",
            "Generation 7: Best Fitness = 0.20205411314964294, Best Individual = [21.810641007002477, 12.287424942982577, 15.55559359890333]\n",
            "Generation 8: Best Fitness = 0.1950589120388031, Best Individual = [26.779534272956603, 9.545048698493122, 13.686252672007425]\n",
            "Generation 9: Best Fitness = 0.1865866780281067, Best Individual = [26.779534272956603, 9.545048698493122, 12.352477897604832]\n",
            "Generation 10: Best Fitness = 0.1865866780281067, Best Individual = [26.779534272956603, 9.545048698493122, 12.352477897604832]\n",
            "Generation 11: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 12: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 13: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 14: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 15: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 16: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 17: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 18: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 19: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 20: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 21: Best Fitness = 0.18401126563549042, Best Individual = [26.779534272956603, 7.72104748764787, 12.352477897604832]\n",
            "Generation 22: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 23: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 24: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 25: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 26: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 27: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 28: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 29: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 30: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 31: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 32: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 33: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 34: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 35: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 36: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 37: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 38: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 39: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 40: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 41: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 42: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 43: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 44: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 45: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 46: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 47: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 48: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 49: Best Fitness = 0.18301518261432648, Best Individual = [26.779534272956603, 7.72104748764787, 12.159889369215993]\n",
            "Generation 50: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 51: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 52: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 53: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 54: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 55: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 56: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 57: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 58: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 59: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 60: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 61: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 62: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 63: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 64: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 65: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 66: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 67: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 68: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 69: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 70: Best Fitness = 0.18244501948356628, Best Individual = [26.779534272956603, 7.961506066716546, 12.026972741409239]\n",
            "Generation 71: Best Fitness = 0.18244501948356628, Best Individual = [26.779534272956603, 7.961506066716546, 12.026972741409239]\n",
            "Generation 72: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 73: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 74: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 75: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 76: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 77: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 78: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 79: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 80: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 81: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 82: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 83: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 84: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 85: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 86: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 87: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 88: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 89: Best Fitness = 0.18299971520900726, Best Individual = [26.779534272956603, 7.688532171583751, 12.159889369215993]\n",
            "Generation 90: Best Fitness = 0.18026895821094513, Best Individual = [26.779534272956603, 10.005277524051209, 11.055572611877462]\n",
            "Generation 91: Best Fitness = 0.18026895821094513, Best Individual = [26.779534272956603, 10.005277524051209, 11.055572611877462]\n",
            "Generation 92: Best Fitness = 0.18026895821094513, Best Individual = [26.779534272956603, 10.005277524051209, 11.055572611877462]\n",
            "Generation 93: Best Fitness = 0.18026895821094513, Best Individual = [26.779534272956603, 10.005277524051209, 11.055572611877462]\n",
            "Generation 94: Best Fitness = 0.1796654313802719, Best Individual = [26.578361905270018, 10.005277524051209, 11.055572611877462]\n",
            "Generation 95: Best Fitness = 0.1796654313802719, Best Individual = [26.578361905270018, 10.005277524051209, 11.055572611877462]\n",
            "Generation 96: Best Fitness = 0.1796654313802719, Best Individual = [26.578361905270018, 10.005277524051209, 11.055572611877462]\n",
            "Generation 97: Best Fitness = 0.1796654313802719, Best Individual = [26.578361905270018, 10.005277524051209, 11.055572611877462]\n",
            "Generation 98: Best Fitness = 0.1796654313802719, Best Individual = [26.578361905270018, 10.005277524051209, 11.055572611877462]\n",
            "Generation 99: Best Fitness = 0.17865346372127533, Best Individual = [26.578361905270018, 9.637632965261151, 11.055572611877462]\n",
            "Best Solution: [26.578361905270018, 9.637632965261151, 11.055572611877462]\n",
            "Best Fitness: 0.17865346372127533\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import random\n",
        "\n",
        "# # تابعی که می‌خواهیم بهینه‌سازی کنیم\n",
        "# def objective_function(x):\n",
        "#     # مثال: تابع راسترگین (Rastrigin function)\n",
        "#     return Cost_function(x)\n",
        "\n",
        "# # تابع برای ایجاد جمعیت اولیه\n",
        "# def create_population(pop_size, var_ranges):\n",
        "#     population = []\n",
        "#     for _ in range(pop_size):\n",
        "#         individual = [random.uniform(rng[0], rng[1]) for rng in var_ranges]\n",
        "#         population.append(individual)\n",
        "#     return population\n",
        "\n",
        "# # تابع برای ارزیابی جمعیت\n",
        "# def evaluate_population(population):\n",
        "#     return [objective_function(individual) for individual in population]\n",
        "\n",
        "# # انتخاب براساس تورنومنت\n",
        "# def tournament_selection(population, fitness, k=3):\n",
        "#     selected = random.sample(list(zip(population, fitness)), k)\n",
        "#     selected.sort(key=lambda ind_fit: ind_fit[1])\n",
        "#     return selected[0][0]\n",
        "\n",
        "# # تابع کراس‌اور (ترکیب دو کروموزوم)\n",
        "# def crossover(parent1, parent2, crossover_rate=0.8):\n",
        "#     if random.random() < crossover_rate:\n",
        "#         point = random.randint(1, len(parent1) - 1)\n",
        "#         child1 = parent1[:point] + parent2[point:]\n",
        "#         child2 = parent2[:point] + parent1[point:]\n",
        "#     else:\n",
        "#         child1, child2 = parent1, parent2\n",
        "#     return child1, child2\n",
        "\n",
        "# # تابع جهش (موتاسیون) با قابلیت تنظیم نرخ جهش برای هر پارامتر\n",
        "# def mutate(individual, mutation_rates, var_ranges):\n",
        "#     for i in range(len(individual)):\n",
        "#         if random.random() < mutation_rates[i]:\n",
        "#             individual[i] = random.uniform(var_ranges[i][0], var_ranges[i][1])\n",
        "#     return individual\n",
        "\n",
        "# # تابع اصلی الگوریتم ژنتیک\n",
        "# def genetic_algorithm(pop_size, var_ranges, generations, crossover_rate=0.9, mutation_rates=None):\n",
        "#     # اگر نرخ‌های جهش تعریف نشده باشند، از نرخ پیش‌فرض 0.02 استفاده می‌کنیم\n",
        "#     if mutation_rates is None:\n",
        "#         mutation_rates = [0.02] * len(var_ranges)\n",
        "\n",
        "#     # ایجاد جمعیت اولیه\n",
        "#     population = create_population(pop_size, var_ranges)\n",
        "\n",
        "#     for generation in range(generations):\n",
        "#         # ارزیابی جمعیت\n",
        "#         fitness = evaluate_population(population)\n",
        "\n",
        "#         # بهترین فرد (برای نمایش)\n",
        "#         best_individual = population[np.argmin(fitness)]\n",
        "#         best_fitness = min(fitness)\n",
        "#         print(f'Generation {generation}: Best Fitness = {best_fitness}, Best Individual = {best_individual}')\n",
        "\n",
        "#         # نسل جدید\n",
        "#         new_population = []\n",
        "\n",
        "#         # انتخاب و ایجاد نسل جدید\n",
        "#         while len(new_population) < pop_size:\n",
        "#             parent1 = tournament_selection(population, fitness)\n",
        "#             parent2 = tournament_selection(population, fitness)\n",
        "\n",
        "#             child1, child2 = crossover(parent1, parent2, crossover_rate)\n",
        "#             child1 = mutate(child1, mutation_rates, var_ranges)\n",
        "#             child2 = mutate(child2, mutation_rates, var_ranges)\n",
        "\n",
        "#             new_population.append(child1)\n",
        "#             new_population.append(child2)\n",
        "\n",
        "#         # جایگزینی جمعیت قدیمی با نسل جدید\n",
        "#         population = new_population[:pop_size]\n",
        "\n",
        "#     # ارزیابی جمعیت نهایی و برگرداندن بهترین جواب\n",
        "#     fitness = evaluate_population(population)\n",
        "#     best_individual = population[np.argmin(fitness)]\n",
        "#     return best_individual, min(fitness)\n",
        "\n",
        "# # پارامترها\n",
        "# pop_size = 30\n",
        "# var_ranges = [(1,53), (1, 21.7),(1,30)]  # محدوده هر پارامتر\n",
        "# generations = 100\n",
        "# mutation_rates = [0.1, 0.1, 0.1]  # نرخ جهش برای هر پارامتر به ترتیب\n",
        "\n",
        "# # اجرای الگوریتم ژنتیک\n",
        "# best_solution, best_fitness = genetic_algorithm(pop_size, var_ranges, generations, mutation_rates=mutation_rates)\n",
        "\n",
        "# print(f'Best Solution: {best_solution}')\n",
        "# print(f'Best Fitness: {best_fitness}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDJyXYuIcyEA",
        "outputId": "74cdce51-9451-4503-d736-a4edf59474d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution: 0\n",
            "Solution: 1\n",
            "Solution: 2\n",
            "Solution: 3\n",
            "Solution: 4\n",
            "Solution: 5\n",
            "Solution: 6\n",
            "Solution: 7\n",
            "Solution: 8\n",
            "Solution: 9\n",
            "Solution: 10\n",
            "Solution: 11\n",
            "Solution: 12\n",
            "Solution: 13\n",
            "Solution: 14\n",
            "Solution: 15\n",
            "Solution: 16\n",
            "Solution: 17\n",
            "Solution: 18\n",
            "Solution: 19\n",
            "Solution: 20\n",
            "Solution: 21\n",
            "Solution: 22\n",
            "Solution: 23\n",
            "Solution: 24\n",
            "Solution: 25\n",
            "Solution: 26\n",
            "Solution: 27\n",
            "Solution: 28\n",
            "Solution: 29\n",
            "Solution: 30\n",
            "Solution: 31\n",
            "Solution: 32\n",
            "Solution: 33\n",
            "Solution: 34\n",
            "Solution: 35\n",
            "Solution: 36\n",
            "Solution: 37\n",
            "Solution: 38\n",
            "Solution: 39\n",
            "Solution: 40\n",
            "Solution: 41\n",
            "Solution: 42\n",
            "Solution: 43\n",
            "Solution: 44\n",
            "Solution: 45\n",
            "Solution: 46\n",
            "Solution: 47\n",
            "Solution: 48\n",
            "Solution: 49\n",
            "Solution: 50\n",
            "Solution: 51\n",
            "Solution: 52\n",
            "Solution: 53\n",
            "Solution: 54\n",
            "Solution: 55\n",
            "Solution: 56\n",
            "Solution: 57\n",
            "Solution: 58\n",
            "Solution: 59\n",
            "Solution: 60\n",
            "Solution: 61\n",
            "Solution: 62\n",
            "Solution: 63\n",
            "Solution: 64\n",
            "Solution: 65\n",
            "Solution: 66\n",
            "Solution: 67\n",
            "Solution: 68\n",
            "Solution: 69\n",
            "Solution: 70\n",
            "Solution: 71\n",
            "Solution: 72\n",
            "Solution: 73\n",
            "Solution: 74\n",
            "Solution: 75\n",
            "Solution: 76\n",
            "Solution: 77\n",
            "Solution: 78\n",
            "Solution: 79\n",
            "Solution: 80\n",
            "Solution: 81\n",
            "Solution: 82\n",
            "Solution: 83\n",
            "Solution: 84\n",
            "Solution: 85\n",
            "Solution: 86\n",
            "Solution: 87\n",
            "Solution: 88\n",
            "Solution: 89\n",
            "Solution: 90\n",
            "Solution: 91\n",
            "Solution: 92\n",
            "Solution: 93\n",
            "Solution: 94\n",
            "Solution: 95\n",
            "Solution: 96\n",
            "Solution: 97\n",
            "Solution: 98\n",
            "Solution: 99\n",
            "Solution: [ 1.        21.7       25.8960518]\n",
            "Fitness: 0.19168978929519653\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "\n",
        "\n",
        "# # Define the Rastrigin function\n",
        "# def rastrigin(x):\n",
        "#     n = len(x)\n",
        "#     return 10*n + sum([xi**2 - 10*np.cos(2*np.pi*xi) for xi in x])\n",
        "\n",
        "# # Define the PSO algorithm\n",
        "# def pso(cost_func, dim=2, num_particles=30, max_iter=100, w=1.2, c1=2, c2=2, param_ranges=None):\n",
        "#     # If param_ranges is not provided, default to [0, 53] for each dimension\n",
        "#     if param_ranges is None:\n",
        "#         param_ranges = np.array([[0, 53]] * dim)\n",
        "\n",
        "#     # Initialize particles within the provided ranges\n",
        "#     particles = np.array([np.random.uniform(low, high, num_particles) for low, high in param_ranges]).T\n",
        "#     velocities = np.zeros((num_particles, dim))\n",
        "\n",
        "#     # Initialize the best positions and fitness values\n",
        "#     best_positions = np.copy(particles)\n",
        "#     best_fitness = np.array([cost_func(p) for p in particles])\n",
        "#     swarm_best_position = best_positions[np.argmin(best_fitness)]\n",
        "#     swarm_best_fitness = np.min(best_fitness)\n",
        "\n",
        "#     # Iterate through the specified number of iterations, updating the velocity and position of each particle at each iteration\n",
        "#     for i in range(max_iter):\n",
        "#         # Update velocities\n",
        "#         r1 = np.random.uniform(0, 1, (num_particles, dim))\n",
        "#         r2 = np.random.uniform(0, 1, (num_particles, dim))\n",
        "#         velocities = w * velocities + c1 * r1 * (best_positions - particles) + c2 * r2 * (swarm_best_position - particles)\n",
        "\n",
        "#         # Update positions\n",
        "#         particles += velocities\n",
        "\n",
        "#         # Ensure particles stay within the bounds\n",
        "#         for j in range(dim):\n",
        "#             particles[:, j] = np.clip(particles[:, j], param_ranges[j][0], param_ranges[j][1])\n",
        "\n",
        "#         # Evaluate fitness of each particle\n",
        "#         fitness_values = np.array([cost_func(p) for p in particles])\n",
        "\n",
        "#         # Update best positions and fitness values\n",
        "#         improved_indices = np.where(fitness_values < best_fitness)\n",
        "#         best_positions[improved_indices] = particles[improved_indices]\n",
        "#         best_fitness[improved_indices] = fitness_values[improved_indices]\n",
        "#         if np.min(fitness_values) < swarm_best_fitness:\n",
        "#             swarm_best_position = particles[np.argmin(fitness_values)]\n",
        "#             swarm_best_fitness = np.min(fitness_values)\n",
        "#         print('Solution:', i)\n",
        "\n",
        "#     # Return the best solution found by the PSO algorithm\n",
        "#     return swarm_best_position, swarm_best_fitness\n",
        "\n",
        "# # Define the dimensions of the problem\n",
        "# dim = 3\n",
        "\n",
        "# # Define parameter ranges for each dimension\n",
        "# param_ranges = np.array([(1,53), (1, 21.7),(1,30)])\n",
        "\n",
        "# # Run the PSO algorithm on the Rastrigin function\n",
        "# solution, fitness = pso(Cost_function, dim=dim, param_ranges=param_ranges)\n",
        "\n",
        "# # Print the solution and fitness value\n",
        "# print('Solution:', solution)\n",
        "# print('Fitness:', fitness)\n",
        "\n",
        "# # # Create a meshgrid for visualization (only valid for 2D visualization)\n",
        "# # x = np.linspace(param_ranges[0][0], param_ranges[0][1], 100)\n",
        "# # y = np.linspace(param_ranges[1][0], param_ranges[1][1], 100)\n",
        "# # X, Y = np.meshgrid(x, y)\n",
        "# # Z = rastrigin([X, Y])\n",
        "\n",
        "# # # Create a 3D plot of the Rastrigin function\n",
        "# # fig = plt.figure()\n",
        "# # ax = fig.add_subplot(111, projection='3d')\n",
        "# # ax.plot_surface(X, Y, Z, cmap='viridis')\n",
        "# # ax.set_xlabel('x')\n",
        "# # ax.set_ylabel('y')\n",
        "# # ax.set_zlabel('z')\n",
        "\n",
        "# # # Plot the solution found by the PSO algorithm (only plotting the first two dimensions)\n",
        "# # ax.scatter(solution[0], solution[1], fitness, color='red')\n",
        "# # plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Et-mork5nYH"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # ایجاد مقادیر ستون‌ها\n",
        "# column1 = np.arange(1, 53, 1)\n",
        "# column2 = np.arange(1, 21.7, 0.1)\n",
        "# column3 = np.arange(1, 30, 0.25)\n",
        "\n",
        "# # ایجاد مش با استفاده از تکرار ستون‌ها\n",
        "# mesh = np.array(np.meshgrid(column1, column2, column3)).T.reshape(-1, 3)\n",
        "\n",
        "# # ایجاد دیتا فریم\n",
        "# df = pd.DataFrame(mesh, columns=['Number of PV panels', 'Electrolyzer Capacity (kW)', 'Tank Volume'])\n",
        "\n",
        "# # نمایش اولین چند ردیف دیتا فریم\n",
        "# print(df.head())\n",
        "# print(f\"Shape of DataFrame: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwbH4ETH5ptG"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD0KoYuJ5quZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# input_param_scaled_clf = clf_scaler.transform(df)\n",
        "# prediction_clf = clf_model.predict(input_param_scaled_clf)\n",
        "\n",
        "\n",
        "\n",
        "# input_param_scaled_reg = reg_scaler.transform(df)\n",
        "# prediction_reg = reg_model.predict(input_param_scaled_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f56RWyrpDhA_"
      },
      "outputs": [],
      "source": [
        "# prediction_clf = (prediction_clf>0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRnG_nB7DukV"
      },
      "outputs": [],
      "source": [
        "# prediction_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWKsA9NRD1H-"
      },
      "outputs": [],
      "source": [
        "# # prompt: add prediction_clf to df\n",
        "\n",
        "# df['Faild'] = prediction_clf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoyqUGyhD753"
      },
      "outputs": [],
      "source": [
        "# df[['Energy Efficiency (%)','LCOE']] = prediction_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teQDrya2FKRH"
      },
      "outputs": [],
      "source": [
        "# # prompt: save df as csv\n",
        "\n",
        "# df.to_csv('output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mDEeI2ZFrIv"
      },
      "outputs": [],
      "source": [
        "# # prompt: remove rows in df which their Failed value are 1\n",
        "\n",
        "# df = df[df['Faild'] == 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_pfDCTUFy6-"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvdnaOymF8sW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N8X4aEuJj4X"
      },
      "outputs": [],
      "source": [
        "# # prompt: insert new column to df which name is \"Cost Function\" and the value of this column is LCOE/Energy Efficiency\n",
        "\n",
        "# df['Cost Function'] = df['LCOE'] / df['Energy Efficiency (%)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEoK6a0OJ2c3"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jecnNh0DoGZI"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('output.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}